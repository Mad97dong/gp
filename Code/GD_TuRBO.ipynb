{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from numpy import linalg as LA\n",
    "import matplotlib.pyplot as pl\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy import optimize\n",
    "import f_class\n",
    "from GP import GP\n",
    "from GP_grad import GP_grad\n",
    "from TrustGD import TrustGD\n",
    "import time\n",
    "from torch.quasirandom import SobolEngine\n",
    "import sobol_seq\n",
    "from utils import *\n",
    "\n",
    "eps = np.sqrt(np.finfo(float).eps)\n",
    "\n",
    "Noise = False\n",
    "Noise_level = 0.00 # noise-free"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High-dimensional $f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5. -5. -5. -5. -5. -5. -5. -5. -5. -5.]\n",
      " [10. 10. 10. 10. 10. 10. 10. 10. 10. 10.]]\n",
      "dim:  10\n"
     ]
    }
   ],
   "source": [
    "objective = f_class.Hartmann_6(Noise, Noise_level)\n",
    "objective = f_class.Ackley(Noise, Noise_level)\n",
    "# objective = f_class.Michalewicz(Noise, Noise_level)\n",
    "# objective = f_class.Schwefel(Noise, Noise_level, dim=20)\n",
    "# objective = f_class.Rosenbrock(Noise, Noise_level)\n",
    "# objective = f_class.Griewank(Noise, Noise_level)\n",
    "# objective = f_class.Levy(Noise, Noise_level, dim=10) \n",
    "# objective = f_class.Rastrigin(Noise, Noise_level, dim=10)\n",
    "# objective = f_class.Shubert_2(Noise, Noise_level)\n",
    "# objective = f_class.Ackley_2(Noise, Noise_level)\n",
    "\n",
    "f = objective.func\n",
    "clean_f = lambda x: f_class.Hartmann_6().func(x)\n",
    "clean_f = lambda x: f_class.Ackley().func(x)\n",
    "# clean_f = lambda x: f_class.Michalewicz().func(x)\n",
    "# clean_f = lambda x: f_class.Schwefel(dim=20).func(x)\n",
    "# clean_f = lambda x: f_class.Rosenbrock().func(x)\n",
    "# clean_f = lambda x: f_class.Griewank().func(x)\n",
    "# clean_f = lambda x: f_class.Levy(dim=10).func(x)\n",
    "# clean_f = lambda x: f_class.Rastrigin(dim=10).func(x)\n",
    "# clean_f = lambda x: f_class.Shubert_2().func(x)\n",
    "# clean_f = lambda x: f_class.Ackley_2().func(x)  \n",
    "\n",
    "B = np.array([item[1] for item in sorted(objective.bounds.items(), key=lambda x: x[0])], dtype=np.float64)\n",
    "print(B.T) \n",
    "lb = B[:, 0]; ub = B[:, 1]\n",
    "\n",
    "dim = objective.input_dim\n",
    "print('dim: ', dim)\n",
    "# print(f( np.array([dim*[1], dim*[1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.43416490252569"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assuming B = L^d, cube\n",
    "Diam = LA.norm(ub - lb)\n",
    "Len = (ub - lb)[0]\n",
    "Diam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding Optimized Hyperparameter $\\sigma, \\ell \\rightarrow$ Online Update of Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 0\n",
    "def random_draw(n_random_draws=3):\n",
    "    \"\"\" samples some points\"\"\"\n",
    "    # should draw randomly\n",
    "    return np.random.uniform(lb, ub, size=(n_random_draws, dim))\n",
    "\n",
    "def optimize_hyper(lb, ub, sample_size=2000):\n",
    "#     np.random.seed(seed)\n",
    "    X = np.asarray(np.random.uniform(lb, ub, size=(sample_size, dim)))\n",
    "    gp.set_data(X, f(X))\n",
    "    ls, var = gp.optimize()\n",
    "    gp.clear()\n",
    "    return (ls, var)\n",
    "\n",
    "# # find optimized hyper, if online, skip this part\n",
    "# gp = GP_grad(B, Noise, Noise_level)\n",
    "# (ls, var) = optimize_hyper(lb, ub, sample_size=2000)\n",
    "# del gp\n",
    "# (ls, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_Grid = dim\n",
    "# G = np.zeros((dim, n_Grid))\n",
    "# for i in range(dim):\n",
    "#     G[i] = np.linspace(lb[i], ub[i], n_Grid)\n",
    "\n",
    "# Grid = np.vstack( [axis.flatten() for axis in np.meshgrid(*(G[i] for i in range(G.shape[0])))] ).T\n",
    "# Grid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Approx Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # approximate the gradient\n",
    "# from scipy import optimize\n",
    "\n",
    "# eps = np.sqrt(np.finfo(float).eps)\n",
    "# approx_grad = np.array([optimize.approx_fprime(x, lambda x: clean_f(x).item(), eps) for x in Grid])\n",
    "# approx_grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3d plot of the gradient\n",
    "# # approximate the gradient\n",
    "# from scipy import optimize\n",
    "\n",
    "# # optimize.approx_fprime(x, clean_Ackley_1d, eps)\n",
    "# eps = np.sqrt(np.finfo(float).eps)\n",
    "# approx_grad = np.array([optimize.approx_fprime(x, lambda x: clean_f(x).item(), eps) for x in Grid])\n",
    "# approx_grad.shape\n",
    "# g1 = approx_grad[:, 0]\n",
    "# g2 = approx_grad[:, 1]\n",
    "# g1, g2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trust Region GD-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX = 200 # function observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Setup with random points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial data\n",
    "setup = 10\n",
    "# X = np.asarray(np.random.uniform(lb, ub, size=(setup, dim)))\n",
    "X = from_unit_cube(latin_hypercube(setup, dim), lb, ub)\n",
    "X_fix = X\n",
    "\n",
    "history = [(x, f(x)) for x in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Build Trust Region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return x inside trust region ball\n",
    "def build_TR(X, TR_c, TR_l):\n",
    "    X_TR = np.vstack(list(filter(lambda x: LA.norm(x - TR_c, np.inf) < TR_l/2, [x for x in X])))\n",
    "    lower_TR = np.maximum(TR_c - TR_l/2, lb)\n",
    "    upper_TR = np.minimum(TR_c + TR_l/2, ub)\n",
    "    return X_TR, np.vstack([lower_TR, upper_TR]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TR_l = 0.8 * Len\n",
    "# X_TR, region_TR = build_TR(X, X[0], TR_l)\n",
    "\n",
    "\n",
    "# pl.figure(figsize=(6, 6), dpi=80)\n",
    "# pl.plot(X[:, 0], X[:, 1], 'o', linewidth=1, markersize=8)\n",
    "# pl.plot(X_TR[:, 0], X_TR[:, 1], 'x', linewidth=2, markersize=8)\n",
    "\n",
    "# pl.xlim(B[0])\n",
    "# pl.ylim(B[1])\n",
    "\n",
    "# pl.gca().add_patch(pl.Rectangle(X[0] - (TR_l/2) * np.ones(dim), TR_l, TR_l, color='blue', alpha=0.1))\n",
    "# pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trust Region GD-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "cost = setup\n",
    "\n",
    "# L0: starting length of trust region\n",
    "S0 = 0.8 * Len\n",
    "S = S0\n",
    "S\n",
    "# gp.posterior(w), gp._normal(f(w))\n",
    "# gp.grad(w), gp.grad_sample(w), optimize.approx_fprime(np.squeeze(w), lambda x: clean_f(x).item(), eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot\n",
    "n_Grid = 100\n",
    "x1 = np.linspace(lb[0], ub[0], n_Grid)\n",
    "x2 = np.linspace(lb[1], ub[1], n_Grid)\n",
    "\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "Grid = np.vstack((X1.flatten(), X2.flatten())).T\n",
    "Grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_Fal = 20\n",
    "MAX_Imp = 3\n",
    "MAX_S = 1.6 * S0\n",
    "MIN_S = (1/2)**7 * S0\n",
    "xc = X[np.argmin(f(X))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".... new lineBO\n",
      "10. S =  12.0\n",
      "prev [12.2565]\n",
      "GD [12.2565]\n",
      "x =  [ 4.1233 -1.8854  3.9517  2.4558 -4.1815 -3.2377  7.9309  0.2897 -4.3767\n",
      "  1.0654]\n",
      "    Normal f(w): -1.2085 \n",
      "    Predict f(w): (0.0000, 0.0500) \n",
      "    f(x): 12.2565 \n",
      "    y best, No:  12.25647316106914 [10]\n",
      "\n",
      "11. S =  12.0\n",
      "prev [12.2565]\n",
      "GD [12.2565]\n",
      "x =  [ 8.8288 -3.3495  7.6932  4.7959 -1.7806  2.4334  6.0573  2.1032  0.9698\n",
      "  1.9835]\n",
      "    Normal f(w): 1.3424 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 13.6719 \n",
      "    y best, No:  12.25647316106914 [10]\n",
      "\n",
      "12. S =  12.0\n",
      "prev [12.2565]\n",
      "GD [12.2565]\n",
      "x =  [ 5.0774 -0.213   6.5941  6.3636 -2.5584  0.98    8.8908  3.0107 -1.9138\n",
      "  5.5099]\n",
      "    Normal f(w): 1.4898 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 14.0610 \n",
      "    y best, No:  12.25647316106914 [10]\n",
      "\n",
      "13. S =  12.0\n",
      "prev [10.8965]\n",
      "GD [10.8965]\n",
      "x =  [ 4.6205  0.7719  0.1201 -2.4361 -2.4839 -4.0734  3.9941  4.2104 -2.8974\n",
      " -1.5946]\n",
      "    Normal f(w): -3.6600 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 10.8965 \n",
      "    y best, No:  10.89654314171262 [13]\n",
      "\n",
      "14. S =  12.0\n",
      "prev [10.8965]\n",
      "GD [10.8965]\n",
      "x =  [ 5.2493 -4.6027  2.997   0.3818 -1.4568 -2.6338 -0.899   8.7886 -0.0828\n",
      " -1.5482]\n",
      "    Normal f(w): 1.4331 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 12.5509 \n",
      "    y best, No:  10.89654314171262 [13]\n",
      "\n",
      "15. S =  12.0\n",
      "prev [10.8965]\n",
      "GD [10.8965]\n",
      "x =  [ 7.9164 -0.9263 -3.4525 -1.4417 -0.5184  0.0517  1.6929  9.8947 -3.1877\n",
      "  4.3698]\n",
      "    Normal f(w): 2.4765 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 13.6858 \n",
      "    y best, No:  10.89654314171262 [13]\n",
      "\n",
      "16. S =  12.0\n",
      "prev [10.8965]\n",
      "GD [10.8965]\n",
      "x =  [ 1.282   0.4204 -1.5104 -3.5294 -4.1039 -4.5741  7.9065  6.1877  2.405\n",
      "  2.46  ]\n",
      "    Normal f(w): 0.8553 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 13.1970 \n",
      "    y best, No:  10.89654314171262 [13]\n",
      "\n",
      "17. S =  12.0\n",
      "prev [10.8965]\n",
      "GD [10.8965]\n",
      "x =  [-0.0892  6.4447 -2.1249 -1.4519  1.2776 -3.3988  1.4842  6.2202  1.7058\n",
      "  3.9267]\n",
      "    Normal f(w): -0.6793 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 11.8712 \n",
      "    y best, No:  10.89654314171262 [13]\n",
      "\n",
      "18. S =  12.0\n",
      "prev [10.8965]\n",
      "GD [10.8965]\n",
      "x =  [-0.4908 -1.861  -2.5964 -2.392  -0.2952  0.6204  9.0591 -1.1578 -2.5453\n",
      "  2.9817]\n",
      "    Normal f(w): -0.7704 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 11.7155 \n",
      "    y best, No:  10.89654314171262 [13]\n",
      "\n",
      "19. S =  12.0\n",
      "prev [10.8965]\n",
      "GD [10.8965]\n",
      "x =  [ 8.0271  3.1857  4.0863  2.2184  3.0155 -3.4927  1.4841  7.0865 -4.0273\n",
      "  1.0386]\n",
      "    Normal f(w): 0.5305 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 12.7714 \n",
      "    y best, No:  10.89654314171262 [13]\n",
      "\n",
      "20. S =  12.0\n",
      "prev [10.8965]\n",
      "GD [10.8965]\n",
      "x =  [ 0.262   2.0204  3.6267 -4.9807  0.6142  1.2141  1.9586  6.7273  2.7557\n",
      " -1.6009]\n",
      "    Normal f(w): -1.5058 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 11.1230 \n",
      "    y best, No:  10.89654314171262 [13]\n",
      "\n",
      "21. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [ 0.2426  1.8504 -1.8371 -3.8592  0.5799  1.2239  4.3684  3.432   0.9857\n",
      "  0.0273]\n",
      "    Normal f(w): -3.6221 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 9.0701 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "22. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [-2.1672 -3.7177  0.4835 -4.0595  3.9201 -3.3955  1.0864 -1.2251  0.4573\n",
      " -2.1404]\n",
      "    Normal f(w): -1.2064 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 9.8132 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "23. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [-1.448   7.1108 -2.06    0.2043  0.0856 -2.7639  8.7357  2.5088  0.9149\n",
      "  1.4922]\n",
      "    Normal f(w): 1.0523 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 12.4285 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "24. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [-4.7674  7.4132 -3.2175 -1.8397  0.9786  0.5184 -0.6019  3.9323  6.8177\n",
      "  4.118 ]\n",
      "    Normal f(w): 1.2627 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 12.8577 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "25. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [-0.8212 -2.6677 -1.1291 -3.5564  4.8588 -4.0242 -0.5859 -1.7261 -3.4857\n",
      "  3.2537]\n",
      "    Normal f(w): -0.5577 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 10.7216 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "26. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [ 2.1708 -2.6587  0.3356 -3.3091  5.175   6.1682 -0.1217 -1.7769  6.8628\n",
      "  5.7445]\n",
      "    Normal f(w): 1.1562 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 12.8071 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "27. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [-1.5819  4.63    3.888  -1.09   -3.7194  1.2146  4.9967  3.9127  1.3785\n",
      "  4.0643]\n",
      "    Normal f(w): -0.1531 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 11.3079 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "28. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [ 4.5937 -1.6331  2.262   0.909   6.202   6.487   9.0947  2.9543 -3.9292\n",
      "  5.27  ]\n",
      "    Normal f(w): 2.2285 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 14.1656 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "29. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [-3.14    7.028  -2.949  -4.4559 -2.258   0.988   2.6357  7.6113 -3.9598\n",
      " -0.3595]\n",
      "    Normal f(w): 0.8815 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 12.8883 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "30. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [ 2.2909  6.4533  3.3263 -3.996   4.418   0.392   2.9971  7.2884  5.2939\n",
      "  3.6185]\n",
      "    Normal f(w): 1.4370 \n",
      "    Predict f(w): (-0.0000, 0.9997) \n",
      "    f(x): 13.7094 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "31. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [-2.6537 -2.7244  2.5168  1.2582  0.4825 -3.1132 -0.8566 -0.3991  4.2509\n",
      " -0.699 ]\n",
      "    Normal f(w): -1.9135 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 9.2519 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "32. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [-4.7143  3.9518 -3.6274 -2.6176 -1.3232  1.7865  3.2312  3.8721  3.1048\n",
      " -2.6857]\n",
      "    Normal f(w): -0.3418 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 11.2304 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "33. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [ 3.069   3.4948 -2.289  -0.4694 -1.2368  3.0089  7.5342  2.2044 -0.1239\n",
      "  5.5123]\n",
      "    Normal f(w): 0.2700 \n",
      "    Predict f(w): (-0.0002, 0.9996) \n",
      "    f(x): 12.1003 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "34. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [-4.0578 -1.5421  3.0762 -0.1982  0.0368  3.6166 -0.0322  7.8082  0.9016\n",
      " -2.6351]\n",
      "    Normal f(w): -0.4584 \n",
      "    Predict f(w): (-0.0001, 0.9996) \n",
      "    f(x): 11.0842 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "35. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [-2.3215  5.0869  2.2936 -0.081   3.0021  1.8459  1.894  -0.144   5.4752\n",
      "  1.4259]\n",
      "    Normal f(w): -1.0093 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 10.3034 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "36. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [-3.1716 -0.4216 -0.4966 -1.2398  4.861   3.2444  5.1312  7.0763  2.6413\n",
      "  4.5651]\n",
      "    Normal f(w): 0.6855 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 12.5727 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "37. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [-0.5027  5.4082 -2.1963 -2.0418  1.915  -4.3317  1.934   2.9197  0.688\n",
      " -3.6232]\n",
      "    Normal f(w): -0.8103 \n",
      "    Predict f(w): (-0.0003, 0.9997) \n",
      "    f(x): 10.5691 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "38. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [-4.2344  2.6572 -2.6112  0.91   -4.7549  3.5266  7.9751  0.3512  1.8063\n",
      "  4.8054]\n",
      "    Normal f(w): 0.8029 \n",
      "    Predict f(w): (0.0000, 0.9997) \n",
      "    f(x): 12.7056 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "39. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [-3.1439  7.1992 -1.156  -1.1866  1.7179  2.6555  2.7363  4.1572 -0.3365\n",
      "  0.4853]\n",
      "    Normal f(w): -0.4466 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 11.0714 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "40. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [-0.829   1.2722  2.2132 -3.0033  1.9632 -0.0145 -0.7976  8.6937  3.5433\n",
      "  5.5762]\n",
      "    Normal f(w): 0.3285 \n",
      "    Predict f(w): (0.0003, 0.9996) \n",
      "    f(x): 12.0764 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "41. S =  12.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "Shrink the region: 6.0000 \n",
      "x =  [-3.4473  2.0684  1.3132 -4.4996 -4.8183  1.3041  0.9939  7.168  -4.5377\n",
      "  3.6684]\n",
      "    Normal f(w): 0.7348 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 12.6107 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "42. S =  6.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [-1.4084  1.9634 -2.1172 -2.3825 -1.3516  1.9805  4.4467  3.0993  1.444\n",
      "  1.0942]\n",
      "    Normal f(w): 0.0749 \n",
      "    Predict f(w): (0.0000, 0.0500) \n",
      "    f(x): 9.1450 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "43. S =  6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [ 3.1837  4.1049  0.1197 -2.0649 -0.6852 -0.0771  2.6522  5.8909  1.4173\n",
      "  2.6605]\n",
      "    Normal f(w): 29.8025 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 10.2234 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "44. S =  6.0\n",
      "prev [9.0701]\n",
      "GD [9.0701]\n",
      "x =  [ 2.2028  4.6691 -2.4261 -4.8712  2.9357  0.6128  2.4128  4.6913  2.857\n",
      "  1.2573]\n",
      "    Normal f(w): 3.3991 \n",
      "    Predict f(w): (0.0013, 0.9369) \n",
      "    f(x): 11.2705 \n",
      "    y best, No:  9.070104739958 [21]\n",
      "\n",
      "45. S =  6.0\n",
      "prev [8.9858]\n",
      "GD [8.9858]\n",
      "x =  [ 0.4182  1.7268 -2.0892 -2.9825 -1.5095  0.9592  4.4661  3.2703  0.3195\n",
      " -0.1851]\n",
      "    Normal f(w): -1.0463 \n",
      "    Predict f(w): (-0.6405, 0.6481) \n",
      "    f(x): 8.9858 \n",
      "    y best, No:  8.985752445467739 [45]\n",
      "\n",
      "46. S =  6.0\n",
      "prev [8.9858]\n",
      "GD [8.9858]\n",
      "x =  [ 3.2552  3.3648 -1.2863 -2.0765 -2.0575 -0.5149  1.7421  5.8843 -2.5633\n",
      "  2.5563]\n",
      "    Normal f(w): 2.4711 \n",
      "    Predict f(w): (0.1183, 0.8951) \n",
      "    f(x): 10.6013 \n",
      "    y best, No:  8.985752445467739 [45]\n",
      "\n",
      "47. S =  6.0\n",
      "prev [8.9858]\n",
      "GD [8.9858]\n",
      "x =  [ 0.0554  1.4645 -3.9507 -1.7063 -2.1333  3.4705  7.3821  4.228  -0.5598\n",
      "  0.3392]\n",
      "    Normal f(w): 2.9344 \n",
      "    Predict f(w): (-0.0605, 0.7973) \n",
      "    f(x): 11.5763 \n",
      "    y best, No:  8.985752445467739 [45]\n",
      "\n",
      "48. S =  6.0\n",
      "prev [8.9858]\n",
      "GD [8.9858]\n",
      "x =  [-0.532   0.4379 -1.0299 -0.5576  0.5871  2.1509  1.5703  5.9319  1.3268\n",
      " -2.7772]\n",
      "    Normal f(w): -0.5951 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 9.3642 \n",
      "    y best, No:  8.985752445467739 [45]\n",
      "\n",
      "49. S =  6.0\n",
      "prev [8.9858]\n",
      "GD [8.9858]\n",
      "x =  [ 2.3661  2.2143 -3.7131 -2.5054 -1.4706 -0.9977  2.3985  1.4997  0.5288\n",
      " -2.256 ]\n",
      "    Normal f(w): -0.8047 \n",
      "    Predict f(w): (-0.0496, 0.8891) \n",
      "    f(x): 9.1215 \n",
      "    y best, No:  8.985752445467739 [45]\n",
      "\n",
      "50. S =  6.0\n",
      "prev [8.91]\n",
      "GD [8.91]\n",
      "x =  [ 0.1381  1.8749 -1.7515 -0.4896 -3.1468 -1.0297  4.9813  3.6578 -0.0152\n",
      "  1.9797]\n",
      "    Normal f(w): -0.9636 \n",
      "    Predict f(w): (-0.0670, 0.9049) \n",
      "    f(x): 8.9100 \n",
      "    y best, No:  8.909993174668973 [50]\n",
      "\n",
      "51. S =  6.0\n",
      "prev [8.91]\n",
      "GD [8.91]\n",
      "x =  [-1.4527  2.6638 -0.342   0.8374 -1.1365 -3.1164  3.2665  6.4048  0.388\n",
      " -0.3078]\n",
      "    Normal f(w): 34.6171 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 10.2592 \n",
      "    y best, No:  8.909993174668973 [50]\n",
      "\n",
      "52. S =  6.0\n",
      "prev [8.91]\n",
      "GD [8.91]\n",
      "x =  [ 2.4517  0.7023 -4.5356  1.8564 -4.198  -0.8454  7.1971  2.334   0.5039\n",
      "  0.349 ]\n",
      "    Normal f(w): 3.4566 \n",
      "    Predict f(w): (-0.0165, 0.9841) \n",
      "    f(x): 11.5243 \n",
      "    y best, No:  8.909993174668973 [50]\n",
      "\n",
      "53. S =  6.0\n",
      "prev [8.91]\n",
      "GD [8.91]\n",
      "x =  [ 1.1447  3.7051  0.0298  1.4865 -2.9058 -3.7956  6.6126  3.127  -0.5882\n",
      "  1.7753]\n",
      "    Normal f(w): 0.9379 \n",
      "    Predict f(w): (-0.0476, 0.9766) \n",
      "    f(x): 10.9236 \n",
      "    y best, No:  8.909993174668973 [50]\n",
      "\n",
      "54. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 0.1271 -0.6418  0.89   -1.0675 -0.7856 -1.511   2.162   4.6561 -0.6502\n",
      " -0.1243]\n",
      "    Normal f(w): -2.4041 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 7.6250 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "55. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [-0.6164 -1.335   1.2811 -1.8668 -2.5034 -2.6469  0.9134  4.7354  0.1849\n",
      "  0.5344]\n",
      "    Normal f(w): 0.2180 \n",
      "    Predict f(w): (-0.5795, 0.8358) \n",
      "    f(x): 8.7770 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "56. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [-0.5405 -0.1751  2.6392 -1.2631 -1.2672 -3.8257  0.3611  4.1703 -0.6179\n",
      " -1.1461]\n",
      "    Normal f(w): 0.0570 \n",
      "    Predict f(w): (-0.0343, 0.9886) \n",
      "    f(x): 8.7039 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "57. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 1.7786 -2.7518  2.7741  1.4025  1.4695 -3.488   2.1644  6.1922 -2.4483\n",
      "  1.7718]\n",
      "    Normal f(w): 4.4402 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 10.8399 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "58. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 0.9604 -1.1457  1.8601 -3.5014 -0.5294  0.8075  1.0103  2.3276 -3.6001\n",
      "  2.3994]\n",
      "    Normal f(w): -0.4145 \n",
      "    Predict f(w): (-0.0192, 1.0036) \n",
      "    f(x): 8.6225 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "59. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 2.6863 -1.0092  2.2823 -3.8587 -0.4363 -0.7422  3.1092  5.8896 -3.2769\n",
      " -1.0365]\n",
      "    Normal f(w): 1.6208 \n",
      "    Predict f(w): (-0.0572, 1.0101) \n",
      "    f(x): 10.2908 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "60. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [-2.5481 -2.6913  1.207   1.0488 -0.9246 -1.7964  2.8316  6.5328  1.4456\n",
      "  1.4969]\n",
      "    Normal f(w): 1.3503 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 10.2960 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "61. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 2.4879 -2.8242 -0.9907 -2.6867  0.6067 -3.2349  3.8827  5.7786 -3.4341\n",
      " -0.0097]\n",
      "    Normal f(w): 1.7567 \n",
      "    Predict f(w): (0.0431, 0.9806) \n",
      "    f(x): 10.8283 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "62. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 2.6777 -3.3775  0.0783  1.14   -2.503  -4.1126 -0.073   7.5501  1.0717\n",
      " -2.5368]\n",
      "    Normal f(w): 1.9982 \n",
      "    Predict f(w): (-0.0021, 0.9458) \n",
      "    f(x): 11.3426 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "63. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 1.1911  1.9405 -0.1502 -2.5395  1.6368 -0.2249  0.8236  5.1854 -0.1349\n",
      "  0.3446]\n",
      "    Normal f(w): -1.1121 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 8.3041 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "64. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 0.4052 -0.4859  0.9659 -1.5326 -2.9159 -0.6662 -0.1683  3.1817 -1.6474\n",
      " -3.1017]\n",
      "    Normal f(w): -1.2928 \n",
      "    Predict f(w): (-0.1104, 0.9277) \n",
      "    f(x): 8.0043 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "65. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 0.3691 -3.5925  1.1371  1.7946 -0.0751  0.428   0.7648  4.1332 -0.9936\n",
      "  1.1511]\n",
      "    Normal f(w): -1.2120 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 7.9654 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "66. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [-1.9437 -1.1225  2.9769 -0.1173 -0.0131 -0.2575 -0.1764  6.1526  0.5762\n",
      " -1.8146]\n",
      "    Normal f(w): -0.5549 \n",
      "    Predict f(w): (-0.0795, 0.9549) \n",
      "    f(x): 8.6059 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "67. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 2.245   0.3584  3.6367 -3.5157 -3.267   0.5886  4.427   5.8817  0.3803\n",
      "  1.4036]\n",
      "    Normal f(w): 1.9927 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 11.4159 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "68. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 1.2922 -1.5693  1.4381  1.6218 -2.6451 -2.221   3.3372  5.3581  1.3945\n",
      "  2.112 ]\n",
      "    Normal f(w): 0.6918 \n",
      "    Predict f(w): (-0.0007, 0.9432) \n",
      "    f(x): 10.1582 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "69. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [-0.9649 -0.7313  1.6064 -2.2975  1.2998 -4.3009  2.6018  4.0834 -1.3368\n",
      "  2.2183]\n",
      "    Normal f(w): 0.1499 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 9.5518 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "70. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 3.0242  0.9251 -0.4957  1.4024 -3.7185 -2.2996  1.4253  6.9892 -3.3799\n",
      " -1.0962]\n",
      "    Normal f(w): 1.3522 \n",
      "    Predict f(w): (-0.0041, 0.9450) \n",
      "    f(x): 10.9390 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "71. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [-1.8611 -3.3168 -0.6397 -3.1298 -2.8725  1.2528  1.9142  7.3233  0.2789\n",
      " -1.8753]\n",
      "    Normal f(w): 1.0786 \n",
      "    Predict f(w): (-0.0124, 0.9381) \n",
      "    f(x): 10.7249 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "72. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 2.2783 -3.6202  3.2453 -0.6888 -2.4971 -2.8336  2.7663  3.5421  1.2875\n",
      " -1.742 ]\n",
      "    Normal f(w): 0.5080 \n",
      "    Predict f(w): (-0.0176, 0.9320) \n",
      "    f(x): 10.1183 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "73. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 1.1698  0.6089 -0.4356 -1.3857 -2.4857 -2.7937  0.6484  6.186   0.9809\n",
      "  0.8106]\n",
      "    Normal f(w): -0.0320 \n",
      "    Predict f(w): (-0.1907, 0.8902) \n",
      "    f(x): 9.5122 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "74. S =  6.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "Shrink the region: 3.0000 \n",
      "x =  [-0.2068 -0.5471 -2.0828 -2.3282 -1.8192 -3.3342  0.8909  4.5584 -1.5262\n",
      " -0.355 ]\n",
      "    Normal f(w): -0.4508 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 9.0388 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "75. S =  3.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 0.1661  0.7569  1.5843 -0.9835 -1.6618 -0.3446  0.9661  5.3022 -1.2713\n",
      " -0.3115]\n",
      "    Normal f(w): 0.5568 \n",
      "    Predict f(w): (0.0000, 0.0500) \n",
      "    f(x): 8.1818 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "76. S =  3.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 0.7668 -0.2413 -0.602  -1.9599  0.0161 -2.6378  1.4946  5.0545 -1.0234\n",
      " -0.2893]\n",
      "    Normal f(w): 1.1161 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 8.2141 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "77. S =  3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 1.0938 -1.4926  1.0791 -0.5419 -1.3293 -2.9921  1.534   3.1568  0.5921\n",
      "  1.2163]\n",
      "    Normal f(w): -1.3980 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 7.6289 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "78. S =  3.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 0.3602 -0.8709 -0.0131 -0.9599 -1.1007 -0.599   3.3438  5.9743 -1.5882\n",
      "  0.9445]\n",
      "    Normal f(w): 3.2698 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 8.8467 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "79. S =  3.0\n",
      "prev [7.625]\n",
      "GD [7.625]\n",
      "x =  [ 1.5019 -1.442   2.0568 -2.3188 -1.4271 -1.4459  1.5552  6.1174  0.0191\n",
      " -0.8738]\n",
      "    Normal f(w): 3.2246 \n",
      "    Predict f(w): (-0.0000, 0.9999) \n",
      "    f(x): 9.5591 \n",
      "    y best, No:  7.6249964607940175 [54]\n",
      "\n",
      "80. S =  3.0\n",
      "prev [6.8553]\n",
      "GD [6.8553]\n",
      "x =  [-1.1776 -0.4322  1.7356 -1.3178 -2.047  -1.0604  1.2514  3.2067 -0.8241\n",
      " -0.995 ]\n",
      "    Normal f(w): -2.1770 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 6.8553 \n",
      "    y best, No:  6.855260847650683 [80]\n",
      "\n",
      "81. S =  3.0\n",
      "prev [6.8553]\n",
      "GD [6.8553]\n",
      "x =  [-1.7383 -0.2396  1.6471 -1.2626 -1.3905 -0.0064  1.2289  4.5505 -0.304\n",
      "  0.2187]\n",
      "    Normal f(w): 1.5598 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 7.8405 \n",
      "    y best, No:  6.855260847650683 [80]\n",
      "\n",
      "82. S =  3.0\n",
      "prev [6.8553]\n",
      "GD [6.8553]\n",
      "x =  [-1.6705  0.3589  2.1346 -0.2329 -0.7155 -2.4396  0.7148  3.7636 -2.1853\n",
      " -1.404 ]\n",
      "    Normal f(w): 1.7410 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 8.1765 \n",
      "    y best, No:  6.855260847650683 [80]\n",
      "\n",
      "83. S =  3.0\n",
      "prev [6.8553]\n",
      "GD [6.8553]\n",
      "x =  [-1.6815 -0.054   2.2802 -2.4158 -1.8629  0.3182  0.7603  2.2506 -1.7287\n",
      " -0.2532]\n",
      "    Normal f(w): -0.7071 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 7.2810 \n",
      "    y best, No:  6.855260847650683 [80]\n",
      "\n",
      "84. S =  3.0\n",
      "prev [6.8553]\n",
      "GD [6.8553]\n",
      "x =  [-2.6169  1.0665  0.8643 -2.4674 -0.9351 -0.6964  0.3734  2.9581  0.1933\n",
      " -2.45  ]\n",
      "    Normal f(w): 0.2139 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 7.6531 \n",
      "    y best, No:  6.855260847650683 [80]\n",
      "\n",
      "85. S =  3.0\n",
      "prev [6.8553]\n",
      "GD [6.8553]\n",
      "x =  [-0.2481  0.4254  2.5514 -0.4093 -0.9389 -2.4204  2.0278  3.5966 -0.2206\n",
      " -2.378 ]\n",
      "    Normal f(w): 1.7975 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 8.3221 \n",
      "    y best, No:  6.855260847650683 [80]\n",
      "\n",
      "86. S =  3.0\n",
      "prev [6.8553]\n",
      "GD [6.8553]\n",
      "x =  [-0.9942  0.1285  1.0389 -2.0348 -2.5633 -2.5417  1.0594  3.7909  0.6104\n",
      " -0.1706]\n",
      "    Normal f(w): -0.0206 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 7.6694 \n",
      "    y best, No:  6.855260847650683 [80]\n",
      "\n",
      "87. S =  3.0\n",
      "prev [6.8553]\n",
      "GD [6.8553]\n",
      "x =  [-1.5439 -1.294   2.3479 -1.2597 -2.1424 -0.0685  0.204   3.7737  0.3892\n",
      " -0.324 ]\n",
      "    Normal f(w): 0.0587 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 7.7035 \n",
      "    y best, No:  6.855260847650683 [80]\n",
      "\n",
      "88. S =  3.0\n",
      "prev [6.8553]\n",
      "GD [6.8553]\n",
      "x =  [-2.0027 -0.0758  1.9541 -1.5491 -0.6794 -2.3834  0.7573  3.9684 -1.4876\n",
      " -1.1052]\n",
      "    Normal f(w): 0.4760 \n",
      "    Predict f(w): (0.0002, 1.0000) \n",
      "    f(x): 7.8769 \n",
      "    y best, No:  6.855260847650683 [80]\n",
      "\n",
      "89. S =  3.0\n",
      "prev [5.8531]\n",
      "GD [5.8531]\n",
      "x =  [-2.2835  0.0605  1.2606 -0.4229 -1.0793  0.2363  0.1983  2.2975 -0.6804\n",
      "  0.1748]\n",
      "    Normal f(w): -4.6724 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 5.8531 \n",
      "    y best, No:  5.853053109456152 [89]\n",
      "\n",
      "90. S =  3.0\n",
      "prev [5.8531]\n",
      "GD [5.8531]\n",
      "x =  [-3.3139 -0.1943  0.2727 -1.0247 -1.392   0.9446 -0.9568  2.0601  0.1287\n",
      "  0.38  ]\n",
      "    Normal f(w): -0.5980 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 6.3517 \n",
      "    y best, No:  5.853053109456152 [89]\n",
      "\n",
      "91. S =  3.0\n",
      "prev [5.8531]\n",
      "GD [5.8531]\n",
      "x =  [-1.8977  1.279   1.574  -1.8247 -1.2628 -0.2925 -0.6441  2.9501 -1.5459\n",
      " -1.0574]\n",
      "    Normal f(w): 0.6833 \n",
      "    Predict f(w): (-0.0646, 0.9789) \n",
      "    f(x): 7.1580 \n",
      "    y best, No:  5.853053109456152 [89]\n",
      "\n",
      "92. S =  3.0\n",
      "prev [5.8531]\n",
      "GD [5.8531]\n",
      "x =  [-1.759  -0.4559  0.3824 -0.0693 -1.142  -0.041  -1.2359  3.4392  0.7963\n",
      "  1.1551]\n",
      "    Normal f(w): -0.3448 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 6.5638 \n",
      "    y best, No:  5.853053109456152 [89]\n",
      "\n",
      "93. S =  3.0\n",
      "prev [5.8154]\n",
      "GD [5.8154]\n",
      "x =  [-2.0171  0.9767 -0.0708 -1.2351 -1.9584  0.4815 -0.3444  2.0739  0.6379\n",
      "  1.0337]\n",
      "    Normal f(w): -1.5815 \n",
      "    Predict f(w): (-0.1241, 0.9739) \n",
      "    f(x): 5.8154 \n",
      "    y best, No:  5.815368274792323 [93]\n",
      "\n",
      "94. S =  3.0\n",
      "prev [5.8154]\n",
      "GD [5.8154]\n",
      "x =  [-2.1052  0.8373  1.1666  0.2201 -0.8068  0.5048 -1.5144  2.7474  0.0049\n",
      "  1.0677]\n",
      "    Normal f(w): 0.2367 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 6.2219 \n",
      "    y best, No:  5.815368274792323 [93]\n",
      "\n",
      "95. S =  3.0\n",
      "prev [5.8154]\n",
      "GD [5.8154]\n",
      "x =  [-1.612  -0.0959  1.0486 -0.5108 -1.6496 -0.0121 -0.713   2.7936 -0.5912\n",
      " -0.1976]\n",
      "    Normal f(w): -0.1491 \n",
      "    Predict f(w): (-0.0104, 0.9999) \n",
      "    f(x): 6.1181 \n",
      "    y best, No:  5.815368274792323 [93]\n",
      "\n",
      "96. S =  3.0\n",
      "prev [5.8154]\n",
      "GD [5.8154]\n",
      "x =  [-3.2578 -0.1067  0.5145 -1.7084 -2.0024  1.6588  0.3946  3.0009  1.3503\n",
      " -0.0947]\n",
      "    Normal f(w): 5.7031 \n",
      "    Predict f(w): (0.0011, 0.9986) \n",
      "    f(x): 7.6596 \n",
      "    y best, No:  5.815368274792323 [93]\n",
      "\n",
      "97. S =  3.0\n",
      "prev [5.8154]\n",
      "GD [5.8154]\n",
      "x =  [-3.4808 -0.0136  0.8147 -0.2507 -3.3966  0.5069 -0.5044  2.7842 -0.7858\n",
      "  0.8662]\n",
      "    Normal f(w): 2.8239 \n",
      "    Predict f(w): (-0.0740, 1.0327) \n",
      "    f(x): 8.0092 \n",
      "    y best, No:  5.815368274792323 [93]\n",
      "\n",
      "98. S =  3.0\n",
      "prev [5.8154]\n",
      "GD [5.8154]\n",
      "x =  [-2.4998  1.7561 -0.6135 -2.6278 -1.4134  0.599   0.2143  0.8277  1.1135\n",
      "  0.5184]\n",
      "    Normal f(w): 0.6541 \n",
      "    Predict f(w): (-0.1767, 0.9818) \n",
      "    f(x): 7.0762 \n",
      "    y best, No:  5.815368274792323 [93]\n",
      "\n",
      "99. S =  3.0\n",
      "prev [5.8154]\n",
      "GD [5.8154]\n",
      "x =  [-1.0581  1.1803  0.6663 -1.5296 -2.0272  0.1982 -0.2148  3.3792 -0.6023\n",
      "  2.0528]\n",
      "    Normal f(w): 0.6345 \n",
      "    Predict f(w): (-0.1369, 0.9668) \n",
      "    f(x): 7.0999 \n",
      "    y best, No:  5.815368274792323 [93]\n",
      "\n",
      "100. S =  3.0\n",
      "prev [5.8154]\n",
      "GD [5.8154]\n",
      "x =  [-3.1922  0.0071  0.2526 -0.6917 -0.5597  0.2172  1.0178  2.5763 -0.0454\n",
      "  1.3456]\n",
      "    Normal f(w): -0.0677 \n",
      "    Predict f(w): (-0.1618, 0.9458) \n",
      "    f(x): 6.6284 \n",
      "    y best, No:  5.815368274792323 [93]\n",
      "\n",
      "101. S =  3.0\n",
      "prev [5.8154]\n",
      "GD [5.8154]\n",
      "x =  [-2.3872  1.3442 -0.5565 -0.7791 -1.0129 -0.7975 -0.6242  2.8255  0.9261\n",
      "  1.1907]\n",
      "    Normal f(w): 0.0407 \n",
      "    Predict f(w): (-0.2227, 0.9368) \n",
      "    f(x): 6.7003 \n",
      "    y best, No:  5.815368274792323 [93]\n",
      "\n",
      "102. S =  3.0\n",
      "prev [5.8154]\n",
      "GD [5.8154]\n",
      "x =  [-2.4483  1.0811 -0.0588 -1.0365 -2.3599  0.9939 -1.7826  1.1896 -0.2284\n",
      "  0.7219]\n",
      "    Normal f(w): -0.5297 \n",
      "    Predict f(w): (-0.1903, 0.9461) \n",
      "    f(x): 6.3281 \n",
      "    y best, No:  5.815368274792323 [93]\n",
      "\n",
      "103. S =  3.0\n",
      "prev [5.8154]\n",
      "GD [5.8154]\n",
      "x =  [-1.8011  1.9395  1.3244 -2.435  -1.3537 -0.6539  0.3511  0.6438  2.024\n",
      "  1.8691]\n",
      "    Normal f(w): 0.9127 \n",
      "    Predict f(w): (0.0067, 0.9668) \n",
      "    f(x): 7.2282 \n",
      "    y best, No:  5.815368274792323 [93]\n",
      "\n",
      "104. S =  3.0\n",
      "prev [5.8154]\n",
      "GD [5.8154]\n",
      "x =  [-3.4867  2.0856 -1.2297 -0.0189 -1.8294 -0.9257 -0.609   3.2589  0.884\n",
      "  2.0423]\n",
      "    Normal f(w): 1.7696 \n",
      "    Predict f(w): (0.0326, 0.9326) \n",
      "    f(x): 7.8051 \n",
      "    y best, No:  5.815368274792323 [93]\n",
      "\n",
      "105. S =  3.0\n",
      "prev [5.8154]\n",
      "GD [5.8154]\n",
      "x =  [-2.3241  2.331   0.6188 -0.6032 -2.4291 -0.573  -0.9155  0.8157  1.0524\n",
      "  2.3693]\n",
      "    Normal f(w): 1.0605 \n",
      "    Predict f(w): (-0.0322, 0.9384) \n",
      "    f(x): 7.4740 \n",
      "    y best, No:  5.815368274792323 [93]\n",
      "\n",
      "106. S =  3.0\n",
      "prev [5.8154]\n",
      "GD [5.8154]\n",
      "x =  [-1.1125  1.0499  0.4171 -1.6047 -3.0811  0.4545 -0.9753  1.1846  0.0197\n",
      "  1.675 ]\n",
      "    Normal f(w): -0.5613 \n",
      "    Predict f(w): (-0.2689, 0.8458) \n",
      "    f(x): 6.4318 \n",
      "    y best, No:  5.815368274792323 [93]\n",
      "\n",
      "107. S =  3.0\n",
      "prev [5.8154]\n",
      "GD [5.8154]\n",
      "x =  [-3.1378  1.882  -0.3106 -1.2004 -0.8081  0.7977 -1.7412  2.1135 -0.1321\n",
      "  1.0422]\n",
      "    Normal f(w): -0.3078 \n",
      "    Predict f(w): (-0.3144, 0.8606) \n",
      "    f(x): 6.5841 \n",
      "    y best, No:  5.815368274792323 [93]\n",
      "\n",
      "108. S =  3.0\n",
      "prev [5.6724]\n",
      "GD [5.6724]\n",
      "x =  [-1.2281  0.1252 -0.5499 -0.9036 -0.6539  0.4065 -0.5306  1.0564 -0.2787\n",
      "  2.5025]\n",
      "    Normal f(w): -1.7231 \n",
      "    Predict f(w): (-0.1678, 0.9336) \n",
      "    f(x): 5.6724 \n",
      "    y best, No:  5.672355845344342 [108]\n",
      "\n",
      "109. S =  3.0\n",
      "prev [5.1061]\n",
      "GD [5.1061]\n",
      "x =  [-0.4562  1.1862 -0.0498 -0.6861 -1.5911  0.4631 -0.796   0.4988  0.1679\n",
      "  1.3102]\n",
      "    Normal f(w): -8.9195 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 5.1061 \n",
      "    y best, No:  5.106063111063541 [109]\n",
      "\n",
      "110. S =  3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev [5.1061]\n",
      "GD [5.1061]\n",
      "x =  [-0.8078  2.468  -0.0424  0.0326 -1.7565  1.228   0.5151  1.1251  0.4299\n",
      "  0.5887]\n",
      "    Normal f(w): 0.3098 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 5.9050 \n",
      "    y best, No:  5.106063111063541 [109]\n",
      "\n",
      "111. S =  3.0\n",
      "prev [5.1061]\n",
      "GD [5.1061]\n",
      "x =  [-1.9037  1.0735  0.1673  0.6087 -1.7178  0.3928  0.362   0.7418  0.8132\n",
      "  2.6829]\n",
      "    Normal f(w): 1.1243 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 6.3140 \n",
      "    y best, No:  5.106063111063541 [109]\n",
      "\n",
      "112. S =  3.0\n",
      "prev [4.7582]\n",
      "GD [4.7582]\n",
      "x =  [-0.7964  0.3932 -0.3342 -1.6524 -0.2973 -1.0034  0.05    1.0868 -1.0967\n",
      "  0.7109]\n",
      "    Normal f(w): -2.3664 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.7582 \n",
      "    y best, No:  4.758179160645263 [112]\n",
      "\n",
      "113. S =  3.0\n",
      "prev [4.7582]\n",
      "GD [4.7582]\n",
      "x =  [-1.0049 -0.698   0.4397 -0.5897  0.8931 -1.5409  1.5154  1.9742 -1.6636\n",
      "  2.0075]\n",
      "    Normal f(w): 9.1603 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 6.5255 \n",
      "    y best, No:  4.758179160645263 [112]\n",
      "\n",
      "114. S =  3.0\n",
      "prev [4.7582]\n",
      "GD [4.7582]\n",
      "x =  [-0.2258  0.4612 -0.6244 -1.8734 -0.1119 -0.7353  0.2603  1.932   0.0564\n",
      "  1.1911]\n",
      "    Normal f(w): -0.4571 \n",
      "    Predict f(w): (-0.0161, 0.9997) \n",
      "    f(x): 5.1138 \n",
      "    y best, No:  4.758179160645263 [112]\n",
      "\n",
      "115. S =  3.0\n",
      "prev [4.7582]\n",
      "GD [4.7582]\n",
      "x =  [-1.8201  0.4601  0.1441 -2.4255  0.8768 -2.4399 -0.8663  1.1774 -1.6961\n",
      " -0.2451]\n",
      "    Normal f(w): 2.0908 \n",
      "    Predict f(w): (-0.0946, 0.9824) \n",
      "    f(x): 6.7957 \n",
      "    y best, No:  4.758179160645263 [112]\n",
      "\n",
      "116. S =  3.0\n",
      "prev [4.7582]\n",
      "GD [4.7582]\n",
      "x =  [ 0.6014  0.8708 -0.4853 -1.1794  1.0237  0.4915 -0.1737  1.9231 -1.451\n",
      "  0.5545]\n",
      "    Normal f(w): -0.2053 \n",
      "    Predict f(w): (-0.0820, 0.9607) \n",
      "    f(x): 5.4892 \n",
      "    y best, No:  4.758179160645263 [112]\n",
      "\n",
      "117. S =  3.0\n",
      "prev [4.7582]\n",
      "GD [4.7582]\n",
      "x =  [-1.7095 -0.6122  0.3876 -2.7724 -0.9538 -1.4064  0.649   1.3495 -0.8361\n",
      " -0.3986]\n",
      "    Normal f(w): 1.2462 \n",
      "    Predict f(w): (-0.0638, 0.9584) \n",
      "    f(x): 6.5807 \n",
      "    y best, No:  4.758179160645263 [112]\n",
      "\n",
      "118. S =  3.0\n",
      "prev [4.7582]\n",
      "GD [4.7582]\n",
      "x =  [-1.5399  1.6149  0.0563 -0.2449 -1.7686 -0.602   1.3818  1.516  -0.3941\n",
      "  1.8692]\n",
      "    Normal f(w): 0.9597 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 6.5151 \n",
      "    y best, No:  4.758179160645263 [112]\n",
      "\n",
      "119. S =  3.0\n",
      "prev [4.7582]\n",
      "GD [4.7582]\n",
      "x =  [-1.1337  1.8464 -0.3126 -1.8903  0.7274 -0.2117 -0.5733  2.0528 -2.2162\n",
      "  0.6498]\n",
      "    Normal f(w): 0.6580 \n",
      "    Predict f(w): (-0.1091, 0.9454) \n",
      "    f(x): 6.3672 \n",
      "    y best, No:  4.758179160645263 [112]\n",
      "\n",
      "120. S =  3.0\n",
      "prev [4.7582]\n",
      "GD [4.7582]\n",
      "x =  [-2.2696  0.4831 -1.1307 -1.9548 -1.1491 -1.4591  1.115   1.1798 -0.114\n",
      "  2.0419]\n",
      "    Normal f(w): 0.6077 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 6.3686 \n",
      "    y best, No:  4.758179160645263 [112]\n",
      "\n",
      "121. S =  3.0\n",
      "prev [4.7582]\n",
      "GD [4.7582]\n",
      "x =  [-2.1579  0.7128 -1.2495 -2.2284 -0.0314 -1.4711  1.1953  0.2363 -0.7805\n",
      " -0.5008]\n",
      "    Normal f(w): 0.3411 \n",
      "    Predict f(w): (-0.0123, 0.9504) \n",
      "    f(x): 6.2069 \n",
      "    y best, No:  4.758179160645263 [112]\n",
      "\n",
      "122. S =  3.0\n",
      "prev [4.7582]\n",
      "GD [4.7582]\n",
      "x =  [-1.3658 -0.7555 -0.7865 -0.3783 -1.172   0.2337  0.8815  2.4748  0.1408\n",
      "  0.7833]\n",
      "    Normal f(w): -0.4522 \n",
      "    Predict f(w): (-0.0326, 0.9490) \n",
      "    f(x): 5.6731 \n",
      "    y best, No:  4.758179160645263 [112]\n",
      "\n",
      "123. S =  3.0\n",
      "prev [4.7582]\n",
      "GD [4.7582]\n",
      "x =  [-2.1859 -0.8634  0.9384 -0.5173 -0.5494 -0.1116 -1.0844  0.7582 -2.1785\n",
      " -0.4422]\n",
      "    Normal f(w): -0.2959 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 5.7617 \n",
      "    y best, No:  4.758179160645263 [112]\n",
      "\n",
      "124. S =  3.0\n",
      "prev [4.7582]\n",
      "GD [4.7582]\n",
      "x =  [-1.4585 -0.113  -1.722  -2.4991  0.7195 -1.0256  1.2184  0.7349 -0.8698\n",
      "  2.175 ]\n",
      "    Normal f(w): 1.0622 \n",
      "    Predict f(w): (-0.0074, 0.9536) \n",
      "    f(x): 6.6236 \n",
      "    y best, No:  4.758179160645263 [112]\n",
      "\n",
      "125. S =  3.0\n",
      "prev [4.7582]\n",
      "GD [4.7582]\n",
      "x =  [ 0.2185  1.0211 -0.4688 -2.4035 -1.1956 -0.2259 -0.9007  1.2982 -1.6439\n",
      "  0.055 ]\n",
      "    Normal f(w): -0.2545 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 5.8285 \n",
      "    y best, No:  4.758179160645263 [112]\n",
      "\n",
      "126. S =  3.0\n",
      "prev [4.7582]\n",
      "GD [4.7582]\n",
      "x =  [ 0.5762 -0.985  -0.7261 -1.419  -0.4705 -1.9391  1.5349  0.2709 -0.2835\n",
      " -0.492 ]\n",
      "    Normal f(w): -0.4258 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 5.7164 \n",
      "    y best, No:  4.758179160645263 [112]\n",
      "\n",
      "127. S =  3.0\n",
      "prev [4.5707]\n",
      "GD [4.5707]\n",
      "x =  [-1.1567  0.7979 -1.0035 -0.3673 -1.4178  0.3594 -0.1246  0.0754 -1.2785\n",
      "  0.0922]\n",
      "    Normal f(w): -2.3039 \n",
      "    Predict f(w): (-0.1717, 0.9489) \n",
      "    f(x): 4.5707 \n",
      "    y best, No:  4.570687552163285 [127]\n",
      "\n",
      "128. S =  3.0\n",
      "prev [4.5707]\n",
      "GD [4.5707]\n",
      "x =  [ 0.195   1.4269 -2.4239 -0.7069 -2.4369 -0.297  -0.6827  0.5992 -1.8728\n",
      " -0.6428]\n",
      "    Normal f(w): 9.3981 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 6.8962 \n",
      "    y best, No:  4.570687552163285 [127]\n",
      "\n",
      "129. S =  3.0\n",
      "prev [4.5707]\n",
      "GD [4.5707]\n",
      "x =  [-1.5444  1.0268 -2.2267  0.0429 -1.4049  0.7941 -1.0486 -1.0096 -2.0575\n",
      "  0.3308]\n",
      "    Normal f(w): 0.7405 \n",
      "    Predict f(w): (-0.0071, 0.9999) \n",
      "    f(x): 6.0162 \n",
      "    y best, No:  4.570687552163285 [127]\n",
      "\n",
      "130. S =  3.0\n",
      "prev [4.5707]\n",
      "GD [4.5707]\n",
      "x =  [-0.9722  1.1939 -2.2079 -0.5746 -2.4667 -0.6329  1.2192 -1.1525 -1.8952\n",
      " -1.2723]\n",
      "    Normal f(w): 1.5449 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 6.8128 \n",
      "    y best, No:  4.570687552163285 [127]\n",
      "\n",
      "131. S =  3.0\n",
      "prev [4.5707]\n",
      "GD [4.5707]\n",
      "x =  [-2.0212  0.9756  0.2832 -1.6589 -1.5026  1.1354  1.108   1.5041  0.1415\n",
      "  0.7515]\n",
      "    Normal f(w): 0.3115 \n",
      "    Predict f(w): (-0.1986, 0.9995) \n",
      "    f(x): 5.9857 \n",
      "    y best, No:  4.570687552163285 [127]\n",
      "\n",
      "132. S =  3.0\n",
      "prev [4.5707]\n",
      "GD [4.5707]\n",
      "x =  [-1.8861  0.1462 -1.0277 -0.8973 -0.1261 -0.8847  1.1792 -0.631  -2.01\n",
      "  0.9964]\n",
      "    Normal f(w): -0.9330 \n",
      "    Predict f(w): (-0.2120, 0.9850) \n",
      "    f(x): 4.9189 \n",
      "    y best, No:  4.570687552163285 [127]\n",
      "\n",
      "133. S =  3.0\n",
      "prev [4.5707]\n",
      "GD [4.5707]\n",
      "x =  [ 0.0333  1.7222 -0.7318 -0.0523 -1.1665  0.7473 -0.9805 -1.0678 -0.9562\n",
      "  1.1638]\n",
      "    Normal f(w): -1.2262 \n",
      "    Predict f(w): (-0.2660, 0.8865) \n",
      "    f(x): 4.5764 \n",
      "    y best, No:  4.570687552163285 [127]\n",
      "\n",
      "134. S =  3.0\n",
      "prev [4.5707]\n",
      "GD [4.5707]\n",
      "x =  [-1.2305  0.254   0.4499  1.1045 -1.2926 -1.0435  1.3458 -0.6239 -2.1316\n",
      " -0.5911]\n",
      "    Normal f(w): 0.3846 \n",
      "    Predict f(w): (-0.1088, 0.9884) \n",
      "    f(x): 5.8532 \n",
      "    y best, No:  4.570687552163285 [127]\n",
      "\n",
      "135. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [-0.2184 -0.6902 -0.5842  0.0628 -0.2599 -0.4978 -0.1197  1.0362 -0.1904\n",
      "  1.5198]\n",
      "    Normal f(w): -1.5260 \n",
      "    Predict f(w): (-0.2953, 0.9335) \n",
      "    f(x): 4.2695 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "136. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [ 0.3517 -1.0087  0.878   0.4606 -0.0398 -1.4345  0.6692  0.3886 -1.3316\n",
      "  2.7119]\n",
      "    Normal f(w): 1.6320 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 6.0832 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "137. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [-1.0842  0.4588 -0.7335 -1.3055 -1.4459 -1.1421  0.3446  1.0209 -0.2227\n",
      "  1.4074]\n",
      "    Normal f(w): 0.3253 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 5.4826 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "138. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [ 0.1272  0.4837 -0.5347  0.1126  0.7601 -1.9947  0.6774 -0.1205 -0.3766\n",
      "  2.0268]\n",
      "    Normal f(w): -0.1443 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 5.1984 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "139. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [-0.0875 -0.5667  0.6468  0.1751 -1.7127 -0.5119  0.5051 -0.3907  0.7249\n",
      "  2.0284]\n",
      "    Normal f(w): 0.1867 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 5.3907 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "140. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [ 0.3377 -1.919  -0.8869  0.3726 -0.0826 -0.3396 -1.4856 -0.2438 -0.7308\n",
      "  2.0354]\n",
      "    Normal f(w): 0.4668 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 5.5554 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "141. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [ 0.6279 -1.1372  0.2157  1.2227  0.5506  0.8437  1.3678  0.7215  1.0577\n",
      "  2.251 ]\n",
      "    Normal f(w): 0.8323 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 5.7689 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "142. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [-0.5372 -1.5279  0.2166 -1.0893  0.4391  0.5332  1.127  -0.243  -0.3175\n",
      "  2.7438]\n",
      "    Normal f(w): 1.3146 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 6.0594 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "143. S =  3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [ 0.9875  0.0833  0.735  -0.9403  0.1264 -0.511   0.8686  2.428  -0.3966\n",
      "  2.691 ]\n",
      "    Normal f(w): 1.3691 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 6.1696 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "144. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [-0.8693 -0.177  -1.5864 -0.0412  0.1324 -1.9923 -1.0113  1.8133 -0.9981\n",
      "  0.2097]\n",
      "    Normal f(w): -0.8726 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 5.0055 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "145. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [-0.3346  0.0431 -0.8718 -1.3151  0.365   0.4764 -1.4923  0.9849  0.8208\n",
      "  0.0511]\n",
      "    Normal f(w): -1.3377 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.7179 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "146. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [-0.1665 -1.769   0.3411  0.6131  0.9011 -1.8759  0.1757  1.4431 -1.1427\n",
      "  1.0616]\n",
      "    Normal f(w): 0.2096 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 5.5192 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "147. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [ 0.8804  0.149   0.845  -0.5198 -0.3736 -0.7936 -0.3175  1.9797 -0.3546\n",
      "  0.5034]\n",
      "    Normal f(w): -1.0358 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 4.8449 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "148. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [-0.8996 -1.3437 -0.5877  0.9014 -1.7425  0.0738 -1.4493 -0.1525 -1.2242\n",
      "  1.623 ]\n",
      "    Normal f(w): 0.7692 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 5.7929 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "149. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [ 0.9626 -0.7432 -0.8161  0.5403  0.2106 -1.6559  0.0611  1.3246  1.0243\n",
      "  2.6815]\n",
      "    Normal f(w): 1.0730 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 5.9754 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "150. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [-1.3838 -2.057   0.5502  0.347  -0.3238 -1.1973  0.1568  0.9398 -1.3657\n",
      "  0.2763]\n",
      "    Normal f(w): 0.2643 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 5.5730 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "151. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [-0.4004 -0.8223 -1.2837 -0.1595 -0.2393  0.1797 -0.6695  2.4577 -1.0874\n",
      "  2.3168]\n",
      "    Normal f(w): 1.4456 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 6.1977 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "152. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [ 0.8845  0.2249  0.4152  1.2225  0.8006 -0.2155  1.2331  2.2183 -0.8939\n",
      "  2.3058]\n",
      "    Normal f(w): 0.9668 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 5.9964 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "153. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [-0.3923 -0.3488 -0.9946 -0.008   0.9074  0.461  -1.2079  1.3918 -1.5397\n",
      "  0.2104]\n",
      "    Normal f(w): -0.7724 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 5.0861 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "154. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [-1.3736  0.7805  0.1881  0.9275 -1.0788 -1.7044  1.1704  0.782   0.2579\n",
      "  2.9208]\n",
      "    Normal f(w): 1.1566 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 6.0968 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "155. S =  3.0\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "Shrink the region: 1.5000 \n",
      "x =  [ 0.831   0.1995 -1.6594 -0.5377 -1.0863 -0.8695  1.1601  0.7607  1.2266\n",
      "  0.6666]\n",
      "    Normal f(w): -0.6501 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 5.1610 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "156. S =  1.5\n",
      "prev [4.2695]\n",
      "GD [4.2695]\n",
      "x =  [-0.8059 -1.1245 -0.0723  0.4832 -0.0778 -0.76   -0.8232  0.6552 -0.8087\n",
      "  1.1822]\n",
      "    Normal f(w): 0.0041 \n",
      "    Predict f(w): (0.0000, 0.0227) \n",
      "    f(x): 4.2735 \n",
      "    y best, No:  4.2694605120602915 [135]\n",
      "\n",
      "157. S =  1.5\n",
      "prev [4.1443]\n",
      "GD [4.1443]\n",
      "x =  [-0.0743 -0.4424 -1.0899  0.0652  0.4448  0.0929 -0.1308  0.3019 -0.4535\n",
      "  1.5078]\n",
      "    Normal f(w): -62.5663 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.1443 \n",
      "    y best, No:  4.1443289070590374 [157]\n",
      "\n",
      "158. S =  1.5\n",
      "prev [4.1443]\n",
      "GD [4.1443]\n",
      "x =  [-0.7196 -0.5195 -1.792   0.2018  0.7758  0.6047 -0.3948  0.4546 -0.33\n",
      "  2.0834]\n",
      "    Normal f(w): 21.3752 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 5.5443 \n",
      "    y best, No:  4.1443289070590374 [157]\n",
      "\n",
      "159. S =  1.5\n",
      "prev [3.9255]\n",
      "GD [3.9255]\n",
      "x =  [ 0.1347 -1.1271 -0.427   0.0075  0.9092 -0.2907 -0.1936  0.5047 -0.6484\n",
      "  1.004 ]\n",
      "    Normal f(w): -1.1497 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 3.9255 \n",
      "    y best, No:  3.9255171595300706 [159]\n",
      "\n",
      "160. S =  1.5\n",
      "prev [3.9255]\n",
      "GD [3.9255]\n",
      "x =  [ 0.106  -0.6538  0.1085 -0.47    0.4873 -0.5537  0.3695  0.9026 -0.9299\n",
      "  0.5257]\n",
      "    Normal f(w): 0.2505 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 4.0623 \n",
      "    y best, No:  3.9255171595300706 [159]\n",
      "\n",
      "161. S =  1.5\n",
      "prev [3.9255]\n",
      "GD [3.9255]\n",
      "x =  [-0.5875 -1.7642 -0.2605 -0.2733  0.7354 -0.6798  0.2021  0.9359 -0.2879\n",
      "  0.8838]\n",
      "    Normal f(w): 6.6967 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.6485 \n",
      "    y best, No:  3.9255171595300706 [159]\n",
      "\n",
      "162. S =  1.5\n",
      "prev [3.9255]\n",
      "GD [3.9255]\n",
      "x =  [ 0.1003 -1.4439 -0.5794 -0.5156  0.8943  0.0293 -0.8011 -0.2265 -0.3732\n",
      "  0.4271]\n",
      "    Normal f(w): 0.6040 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.3601 \n",
      "    y best, No:  3.9255171595300706 [159]\n",
      "\n",
      "163. S =  1.5\n",
      "prev [3.9255]\n",
      "GD [3.9255]\n",
      "x =  [-0.5638 -1.36   -0.5575  0.2846  1.0275 -0.7771 -0.157   0.6224 -0.5426\n",
      "  1.4196]\n",
      "    Normal f(w): 3.3955 \n",
      "    Predict f(w): (-0.0000, 0.9999) \n",
      "    f(x): 5.0875 \n",
      "    y best, No:  3.9255171595300706 [159]\n",
      "\n",
      "164. S =  1.5\n",
      "prev [3.9255]\n",
      "GD [3.9255]\n",
      "x =  [ 0.4938 -1.5951 -1.1375  0.1179  0.1715 -0.9399 -0.895   0.5839  0.0259\n",
      "  1.748 ]\n",
      "    Normal f(w): 1.6061 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 5.0056 \n",
      "    y best, No:  3.9255171595300706 [159]\n",
      "\n",
      "165. S =  1.5\n",
      "prev [3.9255]\n",
      "GD [3.9255]\n",
      "x =  [-0.2955 -1.438  -1.1084  0.2628  1.6428 -0.0239 -0.0897  0.9192 -0.4346\n",
      "  0.5909]\n",
      "    Normal f(w): 1.0839 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.9255 \n",
      "    y best, No:  3.9255171595300706 [159]\n",
      "\n",
      "166. S =  1.5\n",
      "prev [3.9255]\n",
      "GD [3.9255]\n",
      "x =  [ 0.1786 -1.6477 -0.3691 -0.336   0.8096 -0.3454  0.2638  0.9001 -1.2641\n",
      "  0.9003]\n",
      "    Normal f(w): 0.7078 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.8232 \n",
      "    y best, No:  3.9255171595300706 [159]\n",
      "\n",
      "167. S =  1.5\n",
      "prev [3.9255]\n",
      "GD [3.9255]\n",
      "x =  [ 0.4391 -1.4198 -0.8716 -0.0148  0.801  -0.5265 -0.2403  0.9305 -1.1362\n",
      "  1.3066]\n",
      "    Normal f(w): 0.8548 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 4.9083 \n",
      "    y best, No:  3.9255171595300706 [159]\n",
      "\n",
      "168. S =  1.5\n",
      "prev [3.9255]\n",
      "GD [3.9255]\n",
      "x =  [ 0.8361 -0.8799 -0.1305 -0.1755  1.3842 -0.925  -0.5123  0.5372 -0.3455\n",
      "  0.9505]\n",
      "    Normal f(w): -0.3155 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.4604 \n",
      "    y best, No:  3.9255171595300706 [159]\n",
      "\n",
      "169. S =  1.5\n",
      "prev [3.9255]\n",
      "GD [3.9255]\n",
      "x =  [ 0.1876 -0.7228 -1.098  -0.7282  0.7378 -0.5064 -0.2913  0.2291 -0.5835\n",
      "  1.7475]\n",
      "    Normal f(w): 0.6600 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 4.8352 \n",
      "    y best, No:  3.9255171595300706 [159]\n",
      "\n",
      "170. S =  1.5\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.2599 -0.9247 -0.8678  0.6576  0.9835 -0.9911 -0.8897  0.2393 -0.0383\n",
      "  0.637 ]\n",
      "    Normal f(w): -1.7719 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 3.9243 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "171. S =  1.5\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.8339 -0.389  -0.6498  0.8787  0.6266 -0.6486 -1.0407  0.2976 -0.5785\n",
      "  1.1424]\n",
      "    Normal f(w): 1117.8810 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 4.6092 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "172. S =  1.5\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.764  -1.019  -0.8992  0.2632  1.5053 -1.5344 -0.3195  0.6213 -0.184\n",
      "  1.2982]\n",
      "    Normal f(w): 3.6967 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 5.3455 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "173. S =  1.5\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.0623 -1.622  -0.3655  1.0229  1.3312 -0.4828 -0.7777  0.2415  0.1499\n",
      "  1.2176]\n",
      "    Normal f(w): 0.9103 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 4.9856 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "174. S =  1.5\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.8169 -0.2683 -1.3726  0.4609  0.4966 -0.4793 -1.0865  0.1182 -0.5786\n",
      "  0.2068]\n",
      "    Normal f(w): -0.0332 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 4.5392 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "175. S =  1.5\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.5136 -0.8274 -0.6964  0.6275  0.5598 -0.2788 -0.9272  0.6343 -0.6456\n",
      "  0.0128]\n",
      "    Normal f(w): -0.5875 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.2508 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "176. S =  1.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.2255 -0.2063 -0.5786  1.3544  0.9198 -0.9936 -0.5313  0.8622  0.3016\n",
      "  0.2386]\n",
      "    Normal f(w): -0.2315 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.3978 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "177. S =  1.5\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.0596 -1.2221 -1.5437  0.5676  1.0396 -1.0161 -0.6802 -0.2145  0.63\n",
      "  0.8256]\n",
      "    Normal f(w): 0.8668 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.8966 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "178. S =  1.5\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.7739 -0.3336 -1.3254  0.8894  0.318  -0.2602 -1.5096  0.6688 -0.216\n",
      "  0.3762]\n",
      "    Normal f(w): 0.7583 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.8845 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "179. S =  1.5\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "Shrink the region: 0.7500 \n",
      "x =  [-0.9128 -0.7599 -0.7341  0.699   0.559  -0.8746 -1.1168 -0.0887 -0.7635\n",
      "  1.1084]\n",
      "    Normal f(w): -0.3980 \n",
      "    Predict f(w): (0.0001, 1.0000) \n",
      "    f(x): 4.4003 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "180. S =  0.75\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [ 0.1134 -1.2183 -0.5957  0.7006  1.2449 -0.8675 -1.0657  0.4902  0.1872\n",
      "  0.5573]\n",
      "    Normal f(w): 0.7544 \n",
      "    Predict f(w): (0.0000, 0.0500) \n",
      "    f(x): 4.6786 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "181. S =  0.75\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.3301 -1.1726 -1.1522  0.5533  0.9124 -1.2657 -0.662   0.2056 -0.0975\n",
      "  0.5993]\n",
      "    Normal f(w): 0.9583 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.6629 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "182. S =  0.75\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [ 0.0715 -0.7663 -0.5825  0.6761  1.0027 -1.2448 -0.6606  0.269   0.213\n",
      "  0.5859]\n",
      "    Normal f(w): -0.1452 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 4.3709 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "183. S =  0.75\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.5076 -1.0052 -0.8276  0.5053  1.2503 -0.9554 -0.8352 -0.0664  0.296\n",
      "  0.5697]\n",
      "    Normal f(w): 0.2156 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.4751 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "184. S =  0.75\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.3344 -0.7178 -0.9131  0.3964  1.2175 -0.9495 -0.9351  0.5627  0.1711\n",
      "  0.5091]\n",
      "    Normal f(w): 0.1850 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 4.4732 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "185. S =  0.75\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.4914 -0.8358 -0.7256  0.6886  1.1889 -1.3445 -0.826   0.002  -0.2746\n",
      "  0.9167]\n",
      "    Normal f(w): 0.8664 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 4.6486 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "186. S =  0.75\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.3121 -0.9812 -0.7384  0.4483  1.1265 -1.2241 -0.8138  0.1003 -0.2362\n",
      "  0.3694]\n",
      "    Normal f(w): -0.4595 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.3494 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "187. S =  0.75\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.3973 -0.8808 -1.1411  0.2978  1.2943 -0.716  -1.1368  0.5438  0.3269\n",
      "  0.4392]\n",
      "    Normal f(w): 1.7325 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 4.8500 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "188. S =  0.75\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.544  -1.2102 -0.8704  0.4683  1.2614 -0.9699 -1.2551  0.2462  0.321\n",
      "  0.6371]\n",
      "    Normal f(w): 1.9857 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.9943 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "189. S =  0.75\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [ 0.1028 -0.9776 -0.8163  0.9488  0.6291 -1.0957 -0.9493  0.3966 -0.3269\n",
      "  0.3741]\n",
      "    Normal f(w): -1.1901 \n",
      "    Predict f(w): (-0.0233, 0.9983) \n",
      "    f(x): 4.2059 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "190. S =  0.75\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.4993 -0.6105 -1.2088  0.4374  1.198  -1.037  -1.1778 -0.0269  0.2336\n",
      "  0.3841]\n",
      "    Normal f(w): 0.6746 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.7055 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "191. S =  0.75\n",
      "prev [3.9243]\n",
      "GD [3.9243]\n",
      "x =  [-0.4765 -1.2352 -0.9527  0.5326  0.6916 -1.1661 -0.8305  0.0725  0.0986\n",
      "  0.3066]\n",
      "    Normal f(w): -0.5279 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 4.3806 \n",
      "    y best, No:  3.924292854693459 [170]\n",
      "\n",
      "192. S =  0.75\n",
      "prev [3.767]\n",
      "GD [3.767]\n",
      "x =  [-0.0772 -0.7294 -0.5015  0.4143  0.7279 -0.8528 -0.889   0.0449 -0.1445\n",
      "  0.8524]\n",
      "    Normal f(w): -2.7609 \n",
      "    Predict f(w): (-0.0781, 1.0024) \n",
      "    f(x): 3.7670 \n",
      "    y best, No:  3.7670356377909653 [192]\n",
      "\n",
      "193. S =  0.75\n",
      "prev [3.767]\n",
      "GD [3.767]\n",
      "x =  [ 0.2753 -0.6277 -0.4244  0.5801  0.4275 -0.709  -0.7575 -0.0107 -0.4826\n",
      "  0.7619]\n",
      "    Normal f(w): 3.4662 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 4.1182 \n",
      "    y best, No:  3.7670356377909653 [192]\n",
      "\n",
      "194. S =  0.75\n",
      "prev [3.767]\n",
      "GD [3.767]\n",
      "x =  [-0.0301 -0.7689 -0.6836  0.7803  0.3613 -0.6343 -0.8097 -0.0144  0.072\n",
      "  1.1404]\n",
      "    Normal f(w): -0.5403 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 3.8589 \n",
      "    y best, No:  3.7670356377909653 [192]\n",
      "\n",
      "195. S =  0.75\n",
      "prev [3.767]\n",
      "GD [3.767]\n",
      "x =  [ 0.0266 -0.4088 -0.472   0.6179  0.5034 -0.7797 -0.7411  0.3351 -0.3379\n",
      "  0.7586]\n",
      "    Normal f(w): 1.2535 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 4.0786 \n",
      "    y best, No:  3.7670356377909653 [192]\n",
      "\n",
      "196. S =  0.75\n",
      "prev [3.7081]\n",
      "GD [3.7081]\n",
      "x =  [ 0.2965 -0.9398 -0.441   0.0572  0.6014 -0.8512 -0.7007  0.1602 -0.0214\n",
      "  0.7928]\n",
      "    Normal f(w): -1.8264 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 3.7081 \n",
      "    y best, No:  3.708120628308777 [196]\n",
      "\n",
      "197. S =  0.75\n",
      "prev [3.7081]\n",
      "GD [3.7081]\n",
      "x =  [ 0.6706 -1.0237 -0.2042  0.3492  0.5797 -0.6961 -0.7557  0.2146 -0.3557\n",
      "  0.696 ]\n",
      "    Normal f(w): 14.6013 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 4.1677 \n",
      "    y best, No:  3.708120628308777 [196]\n",
      "\n",
      "198. S =  0.75\n",
      "prev [3.7081]\n",
      "GD [3.7081]\n",
      "x =  [-0.0707 -1.2816 -0.3019 -0.2345  0.495  -0.7068 -0.8246  0.2965 -0.2045\n",
      "  0.5401]\n",
      "    Normal f(w): 1.1421 \n",
      "    Predict f(w): (-0.0000, 1.0000) \n",
      "    f(x): 4.1141 \n",
      "    y best, No:  3.708120628308777 [196]\n",
      "\n",
      "199. S =  0.75\n",
      "prev [3.7081]\n",
      "GD [3.7081]\n",
      "x =  [ 0.6479 -0.8628 -0.331   0.0481  0.2915 -0.9708 -0.4953 -0.0765  0.2624\n",
      "  1.0904]\n",
      "    Normal f(w): -0.5233 \n",
      "    Predict f(w): (0.0000, 1.0000) \n",
      "    f(x): 3.8327 \n",
      "    y best, No:  3.708120628308777 [196]\n",
      "\n",
      "200. S =  0.75\n",
      "prev [3.7081]\n",
      "GD [3.7081]\n",
      "x =  [-0.0435 -1.1951 -0.4711  0.2135  0.5788 -0.767  -0.8707  0.5009 -0.0087\n",
      "  1.0964]\n",
      "    Normal f(w): 1.3883 \n",
      "    Predict f(w): (-0.0004, 1.0000) \n",
      "    f(x): 4.1776 \n",
      "    y best, No:  3.708120628308777 [196]\n",
      "\n",
      "Max Cost reached =  201\n"
     ]
    }
   ],
   "source": [
    "while MAX >= cost:\n",
    "    print('.... new lineBO')\n",
    "    # re-start\n",
    "    if cost != setup:\n",
    "        S = S0\n",
    "        xc = np.random.uniform(lb, ub, size=(1, dim))\n",
    "        X = np.vstack([X, xc])\n",
    "        cost += 1\n",
    "    \n",
    "    f_xc = f(xc)\n",
    "    GD_Fal = 0\n",
    "    GD_Imp = 0\n",
    "    \n",
    "    Xtr, Rtr = build_TR(X, xc, S)\n",
    "    while S >= MIN_S and MAX >= cost:\n",
    "        print(cost, end = '. ')\n",
    "        print('S = ', S)\n",
    "        \n",
    "        # fit a new GP with pts inside TR\n",
    "        gp = GP_grad(Rtr, Noise, Noise_level, compress=True)\n",
    "        gp.set_data(Xtr, f(Xtr))\n",
    "        ls, var = gp.optimize()\n",
    "        gp.set_hyper(ls, var)\n",
    "        gp.fit()\n",
    "        \n",
    "#         x = gp.thompson_sample(n_mesh=5000)\n",
    "        \n",
    "        # GD from xc to get new x\n",
    "        GD = TrustGD(gp, xc, f, S)\n",
    "        x, _ = GD.update(commit=True)\n",
    "        X = np.vstack([X, x])\n",
    "        cost += 1\n",
    "\n",
    "        # update GD_Fal & GD_Imp\n",
    "        delta = np.abs(1e-3 * f_xc)\n",
    "        if f(x) < f_xc - delta:\n",
    "            GD_Fal = 0\n",
    "            GD_Imp += 1\n",
    "        else:\n",
    "            GD_Fal += 1\n",
    "            GD_Imp = 0\n",
    "            \n",
    "        if f(x) < f_xc:\n",
    "            # shift xc\n",
    "            xc = x\n",
    "            f_xc = f(xc)\n",
    "            \n",
    "        # tune xc a little\n",
    "        for i in range(10):\n",
    "            gp.add_data(x, f(x))\n",
    "            ls, var = gp.optimize()\n",
    "            gp.set_hyper(ls, var)\n",
    "            gp.fit()\n",
    "\n",
    "            lr = 0.1 * MIN_S\n",
    "            gt = gp.grad_sample(xc)\n",
    "            gt = gt / LA.norm(gt)\n",
    "            xc = np.clip(xc - lr * gt, gp.B[:, 0], gp.B[:, 1])\n",
    "            \n",
    "        # update S\n",
    "        if MAX_Fal == GD_Fal:\n",
    "            S = S / 2\n",
    "            GD_Fal = 0\n",
    "            print('Shrink the region: %.4f ' % S)\n",
    "\n",
    "        if MAX_Imp == GD_Imp:\n",
    "            S = min(S * 2, MAX_S)\n",
    "            GD_Imp = 0\n",
    "            print('Expand the region: %.4f ' % S)\n",
    "          \n",
    "        # new TR = (xc, R)\n",
    "        Xtr, Rtr = build_TR(X, xc, S)  # get the points only inside the trust region and the region of TR\n",
    "        \n",
    "        # plot\n",
    "#         pl.figure(figsize=(6, 6), dpi=80)\n",
    "#         pl.plot(X[:, 0], X[:, 1], 'o', linewidth=1, markersize=6)\n",
    "#         pl.plot(Xtr[:, 0], Xtr[:, 1], 'x', linewidth=1, markersize=6)\n",
    "\n",
    "#         pl.xlim(B[0])\n",
    "#         pl.ylim(B[1])\n",
    "        \n",
    "#         pl.gca().add_patch(pl.Rectangle(np.squeeze(xc) - (S/2) * np.ones(dim), S, S, color='blue', alpha=0.1))\n",
    "#         pl.contour(X1, X2, f(Grid).reshape(X1.shape),  cmap=\"PuBuGn\") \n",
    "#         pl.show()\n",
    "        \n",
    "        # verbose\n",
    "        print('x = ', x)\n",
    "        print('    Normal f(w): %.4f ' % gp._normal(f(x).item()) )\n",
    "        print('    Predict f(w): (%.4f, %.4f) ' % gp.posterior(x))\n",
    "        print('    f(x): %.4f ' % f(x).item())\n",
    "        \n",
    "        history.append( (x, f(x)) )\n",
    "\n",
    "        # print out y_best, cost\n",
    "        y_best = np.min(f(X))\n",
    "        arg_y_best = np.argmin(f(X))\n",
    "        print('    y best, No: ', y_best, [arg_y_best])\n",
    "        print()\n",
    "        \n",
    "print('Max Cost reached = ', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-2932aa1215d3>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  pl.plot(np.squeeze(np.array(history)[:, 1]), \".\", lw=0.5, markersize=8)\n",
      "<ipython-input-16-2932aa1215d3>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  pl.plot(np.minimum.accumulate(np.array(history)[:, 1]), 'r', lw=3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x560 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.figure(figsize=(10, 7), dpi=80)\n",
    "pl.plot(np.squeeze(np.array(history)[:, 1]), \".\", lw=0.5, markersize=8)\n",
    "pl.xlabel(\"cost\")\n",
    "\n",
    "pl.plot(np.minimum.accumulate(np.array(history)[:, 1]), 'r', lw=3)\n",
    "pl.ylabel(\"function value\")\n",
    "# pl.ylim([0, 25])\n",
    "pl.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minima of GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.022 , -0.0664, -0.0131, -0.0897, -0.0705, -0.061 ,  0.0116,\n",
       "         0.0105, -0.0842,  0.0846]),\n",
       " 0.42375419518758806,\n",
       " 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.X[np.argmin(gp.y)], np.min(gp.y), np.argmin(gp.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.010046032486827, 2.5899310610964426)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.get_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only for backtracking\n",
    "# pl.figure(figsize=(10, 6), dpi=80)\n",
    "# # pl.plot(history_lr, \"-^\")\n",
    "# pl.title(\"learning rate as the algorithm runs\")\n",
    "# pl.xlabel(\"n_iter\")\n",
    "# pl.ylabel(\"learning rate\")\n",
    "# pl.yscale(\"log\")\n",
    "# pl.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TuRBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Thompson Sampling, UCB*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Thompson Sampling\n",
    "import os\n",
    "gp.clear()\n",
    "# gp.set_hyper(ls, var) # if online update hyper, skip\n",
    "\n",
    "# init cost\n",
    "# X = np.asarray(np.random.uniform(lb, ub, size=(setup, dim)))\n",
    "X = X_fix\n",
    "\n",
    "gp.set_data(X, f(X))\n",
    "gp.optimize()\n",
    "gp.fit()\n",
    "\n",
    "history_ucb = []\n",
    "for a in X_fix:\n",
    "    history_ucb.append( (a, f(a)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10. w:  [-2.9708  7.9098  9.4221 -4.0053  1.6135 -3.4827 -4.0064 -4.5825  6.7736\n",
      "  3.2006]\n",
      "  f(w):  14.750124728125018\n",
      "  y_best:  12.745884822492366\n",
      "\n",
      "11. w:  [ 3.4942  0.8941  2.9477  1.1468  2.9419  9.0332  8.535   5.0797 -3.0149\n",
      " -1.6345]\n",
      "  f(w):  13.534869049727783\n",
      "  y_best:  12.745884822492366\n",
      "\n",
      "12. w:  [ 3.1126e-02  4.6312e-01  5.9026e+00 -3.6032e+00  7.7876e+00  9.6626e+00\n",
      "  5.1374e+00  2.2563e-03  3.3669e-01  5.2061e+00]\n",
      "  f(w):  14.321720718351742\n",
      "  y_best:  12.745884822492366\n",
      "\n",
      "  # Optimal (ls, var) =  (0.6426335219372731, 0.9999999818513834)\n",
      "13. w:  [ 5.9089 -0.899  -1.6398 -3.0889  6.2784  2.5464  1.6812  3.4562  8.7511\n",
      "  1.3984]\n",
      "  f(w):  13.434938602650307\n",
      "  y_best:  12.745884822492366\n",
      "\n",
      "14. w:  [-3.1661  9.0737  7.7185  9.0847  0.857   4.8028 -0.5554  2.016   0.4084\n",
      "  8.0717]\n",
      "  f(w):  14.988935800406532\n",
      "  y_best:  12.745884822492366\n",
      "\n",
      "15. w:  [-3.921   1.4678 -4.6091  9.5364  0.286   8.5358 -0.8271  0.1427  0.914\n",
      "  9.9346]\n",
      "  f(w):  15.083842228605235\n",
      "  y_best:  12.745884822492366\n",
      "\n",
      "  # Optimal (ls, var) =  (0.07963603943474654, 1.0000000765322388)\n",
      "16. w:  [7.4428 2.834  8.4972 3.1924 4.2148 5.4935 1.1176 0.4488 2.4206 8.5017]\n",
      "  f(w):  15.01510511869619\n",
      "  y_best:  12.745884822492366\n",
      "\n",
      "17. w:  [ 3.4989 -0.6806  0.9353  3.2785 -2.4673  0.6747  1.5842  2.2948  4.5201\n",
      " -1.7859]\n",
      "  f(w):  9.907838824478121\n",
      "  y_best:  12.745884822492366\n",
      "\n",
      "18. w:  [-4.8948 -0.8484  2.0193  2.9245  5.2566 -1.7211 -3.9188 -3.6263 -3.514\n",
      " -1.6101]\n",
      "  f(w):  11.303001811418223\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "  # Optimal (ls, var) =  (0.6763575884099143, 1.0000001578465751)\n",
      "19. w:  [ 7.9656  4.0175  8.4747 -2.5811  8.4268  1.4026  1.3615  8.5274 -2.5246\n",
      " -2.8973]\n",
      "  f(w):  15.560815757937645\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "20. w:  [ 0.1581  8.8135  6.3131  7.3836  6.815   5.6651 -0.2991  2.8051  5.3652\n",
      " -1.0747]\n",
      "  f(w):  14.891507840485076\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "21. w:  [-4.4541 -1.211  -4.8275  7.3249  8.8143  6.4157  8.4636  7.5669  0.2119\n",
      "  7.3168]\n",
      "  f(w):  16.345266504024195\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "  # Optimal (ls, var) =  (1.4576289708081651, 0.9999999507263064)\n",
      "22. w:  [ 8.6076  9.6919 -2.9952 -0.1573 -3.7635  2.6453  8.5638 -1.6086 -4.6099\n",
      "  9.4192]\n",
      "  f(w):  16.219814409440687\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "23. w:  [ 5.663   0.9056 -4.8653 -2.9603 -1.7577 -4.0481  7.9639 -0.6661  9.9461\n",
      "  1.8076]\n",
      "  f(w):  13.771274905107962\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "24. w:  [-2.4409  3.7622 -0.0937 -3.0671 -0.0499 -4.6284 -4.8514 -0.944   2.6911\n",
      "  3.8943]\n",
      "  f(w):  10.65308086189629\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "  # Optimal (ls, var) =  (1.1912866095659072, 1.0000001738934496)\n",
      "25. w:  [ 6.9265  8.1312  2.6841 -4.3524  8.5093  1.8126  3.9405 -2.2046 -4.228\n",
      " -4.509 ]\n",
      "  f(w):  14.673524494887339\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "26. w:  [ 7.9802  1.6185  4.6147  0.8987  3.3723 -1.9325  2.0852  6.5522  0.1359\n",
      " -2.225 ]\n",
      "  f(w):  12.501859988145885\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "27. w:  [ 4.9997  6.3601  9.5971  5.8589 -4.853  -2.4078  2.0053  8.4617  6.9067\n",
      "  3.4485]\n",
      "  f(w):  15.673002296616353\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "  # Optimal (ls, var) =  (1.0069600696730094, 0.9999999913770347)\n",
      "28. w:  [-2.2475 -0.1618 -1.1617 -2.0886  7.4709  1.8862  7.6649  7.8887 -3.6506\n",
      "  6.2242]\n",
      "  f(w):  14.095035187035823\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "29. w:  [ 5.0792  1.2299  3.9654  8.2696 -3.8698  5.5937  8.4532 -1.9892 -1.5851\n",
      "  0.3843]\n",
      "  f(w):  14.130563254823958\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "30. w:  [-0.1826 -1.092   3.5081  5.4921 -3.0396  0.541   2.7599  2.958   0.115\n",
      " -4.9269]\n",
      "  f(w):  10.669109010401607\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "  # Optimal (ls, var) =  (0.4240561116160291, 1.0000001732420294)\n",
      "31. w:  [ 6.7062  5.04   -1.4663  7.2351  8.958   4.6447 -2.6397  1.3363  1.5818\n",
      "  5.0023]\n",
      "  f(w):  14.629333403936789\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "32. w:  [ 9.5542  1.1609 -0.6579  9.9803  3.5429 -3.9346  2.8794  7.4302  0.2381\n",
      "  8.9237]\n",
      "  f(w):  15.653163226775629\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "33. w:  [ 5.0791 -1.5127  5.0632 -4.0565 -1.5562 -4.8782  2.0181 -1.7812 -2.8158\n",
      "  5.7141]\n",
      "  f(w):  12.025288950642036\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "  # Optimal (ls, var) =  (1.1272970420656336, 1.0000002549869236)\n",
      "34. w:  [ 8.6968  3.1839  0.1791  5.3222  2.1719 -0.1665  8.8846 -3.8078  4.8597\n",
      "  1.423 ]\n",
      "  f(w):  13.970451463382654\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "35. w:  [ 5.3605  2.8071  9.8596  4.8708  3.17    4.8103 -2.7781 -2.1501  9.9082\n",
      " -3.326 ]\n",
      "  f(w):  14.824101269385\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "36. w:  [-2.0683  3.6147 -1.1646  3.6894  4.4856  0.6126  2.8676 -0.2016 -0.25\n",
      " -0.6386]\n",
      "  f(w):  9.647632107904009\n",
      "  y_best:  9.907838824478121\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9998133692989712)\n",
      "37. w:  [ 7.9506 -4.8572  6.1442  8.8302  5.536   8.1384  6.9107 -1.9809 -1.8206\n",
      "  4.8767]\n",
      "  f(w):  15.16811575944048\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "38. w:  [ 9.056   5.1242  3.4447  1.2488  5.1594 -4.6054 -1.1283  0.7092  5.7154\n",
      "  1.7982]\n",
      "  f(w):  13.56700410931824\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "39. w:  [ 9.8229  5.4804 -3.3888  4.1644  2.2203  2.3734  3.2666 -0.1972  3.4181\n",
      "  2.8761]\n",
      "  f(w):  13.596275428388363\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (1.1566095280918136, 1.0000002479645478)\n",
      "40. w:  [ 8.3948  3.9954  9.8927 -3.4362  8.3694 -2.6618  2.9989  5.2027  4.5378\n",
      " -3.4695]\n",
      "  f(w):  15.672372030058824\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "41. w:  [-1.0913  5.464   6.9796  3.4691  9.1505  2.5278  1.6705  0.4116 -1.1649\n",
      " -1.5232]\n",
      "  f(w):  13.534291317016056\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "42. w:  [ 5.9385  6.142   5.446  -1.3657  6.616   9.963   0.5471  3.2041  1.2522\n",
      " -1.9583]\n",
      "  f(w):  14.508044337934829\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (0.08689181350923703, 0.999999990817632)\n",
      "43. w:  [ 3.6658  1.1245 -3.4969 -3.6678  7.7737 -1.8938  8.5061  8.9365 -3.0768\n",
      "  9.9885]\n",
      "  f(w):  15.596520162055345\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "44. w:  [ 7.8493  6.9602 -4.8697 -3.9951  2.271   9.8855 -2.8123  9.3877 -3.8326\n",
      "  9.1793]\n",
      "  f(w):  15.918041278788724\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "45. w:  [ 2.619   0.1819 -3.4447 -0.0524 -2.2237  7.2611  2.6211  4.6955  8.6564\n",
      "  4.679 ]\n",
      "  f(w):  13.783634077263978\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9998153087050415)\n",
      "46. w:  [ 7.6994  8.8651 -3.9472 -3.8459  5.5833 -2.3213  0.3252 -0.2992  9.5262\n",
      "  8.1755]\n",
      "  f(w):  15.790840513462351\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "47. w:  [ 5.3432  1.9391 -3.6831  9.4599  6.1285  7.7722 -4.6801  9.9384  1.0637\n",
      "  2.738 ]\n",
      "  f(w):  15.596028049750299\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "48. w:  [ 3.0278  7.8643  7.9672 -3.3365  1.6106 -2.1217  9.2114  9.2335  7.6316\n",
      " -4.0556]\n",
      "  f(w):  15.745507420196247\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (0.881397776081496, 0.9999995725562887)\n",
      "49. w:  [-3.8721  4.7648  9.1592  1.9338  7.9847  2.108  -0.1499 -2.3228  7.7601\n",
      " -1.0908]\n",
      "  f(w):  13.850052687251267\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "50. w:  [-4.503   0.7396  9.7393  5.6652  8.7231 -0.1982  7.8699  1.7869  8.1149\n",
      "  9.4414]\n",
      "  f(w):  16.515986967738762\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "51. w:  [-3.9243  7.1845  8.4196  9.7708  5.381   8.8313 -2.7131  8.1974  6.7697\n",
      " -3.1172]\n",
      "  f(w):  16.510803430959285\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9998225907613011)\n",
      "52. w:  [-4.8761  0.584   4.9112 -4.6329 -1.3357  1.2365  2.7818  6.6313  1.0748\n",
      "  6.1279]\n",
      "  f(w):  12.73531553729443\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "53. w:  [ 2.6365 -4.7577  2.5603  5.3687  7.2729  8.4216 -4.0782  5.5997 -3.3655\n",
      "  4.043 ]\n",
      "  f(w):  14.816532299351564\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "54. w:  [ 1.1563 -2.5083  2.5447 -2.9     2.3259  4.9009 -1.0541  5.8967 -0.1948\n",
      "  6.4197]\n",
      "  f(w):  11.86801307792421\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (0.2951433706709833, 0.9999999666185696)\n",
      "55. w:  [-2.39    3.1338  6.9755 -2.9447  4.8614 -4.08    8.5685 -4.2593 -0.9475\n",
      "  1.9502]\n",
      "  f(w):  13.17609657685139\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "56. w:  [-4.4147  7.8007 -4.0098 -0.9243  6.6936  9.2043 -0.3879 -4.4185  4.1258\n",
      "  5.1899]\n",
      "  f(w):  14.837444968293429\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "57. w:  [-3.5547 -0.761  -1.1873  0.8919  3.3287  4.6878  0.3291  1.0713 -2.1061\n",
      " -3.518 ]\n",
      "  f(w):  9.81361029019828\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (0.6887569930744528, 1.0000000099932311)\n",
      "58. w:  [ 3.3276  7.453  -2.7141  2.5604  6.1266  5.7876 -4.5636  2.4543  5.5789\n",
      " -1.8649]\n",
      "  f(w):  14.08477774776207\n",
      "  y_best:  9.647632107904009\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59. w:  [ 4.9879  3.3068  9.9317 -0.1059 -3.6545  1.5059  5.7612  3.9657  2.2322\n",
      "  3.4209]\n",
      "  f(w):  13.706411634689882\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "60. w:  [ 0.4492 -3.2203  4.7759  3.5798  5.838  -4.3799  0.9159  9.025  -3.5863\n",
      " -1.8605]\n",
      "  f(w):  13.510822959553572\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (0.9772620664418414, 0.9999999759931035)\n",
      "61. w:  [ 8.5755  7.9293 -1.1431  0.6078 -2.5505  8.2137  7.6275 -0.3505  4.3384\n",
      " -0.6356]\n",
      "  f(w):  15.184916808573336\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "62. w:  [ 4.8916 -4.9046  5.4557  7.7557 -4.3698  1.3536 -1.1063  2.0261  0.897\n",
      "  3.2907]\n",
      "  f(w):  12.885730268811445\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "63. w:  [-0.3909  3.5814  2.9704  0.7839  7.8519  1.0819  4.4976 -1.0415  7.7077\n",
      "  6.3674]\n",
      "  f(w):  13.653844904387608\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (0.20581195458945886, 0.9999999649915683)\n",
      "64. w:  [-0.0161  4.3573  9.0148 -2.5212 -2.3173 -4.3924  7.6042  1.7851  3.9109\n",
      "  0.8288]\n",
      "  f(w):  13.69635897703931\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "65. w:  [ 3.9194 -0.4687 -1.4665  9.9466 -0.9909 -1.3118 -1.2592  0.504  -4.1137\n",
      "  5.6301]\n",
      "  f(w):  12.995975769164335\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "66. w:  [ 4.8486  6.5462  9.4119  9.2536  6.5753  5.48   -3.4576  6.4663 -3.2667\n",
      "  0.9876]\n",
      "  f(w):  16.224040209927953\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (1.235059321597911, 0.999999976729131)\n",
      "67. w:  [ 3.9339  2.4128  5.2615 -2.4728 -0.5945 -2.8292  1.0467 -4.3356  2.4508\n",
      " -1.7163]\n",
      "  f(w):  11.011862128442388\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "68. w:  [ 5.1203 -4.2718  1.4766  7.7075  8.1169  7.5971 -3.5085 -0.3893  1.2311\n",
      " -3.7253]\n",
      "  f(w):  14.693964193153603\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "69. w:  [ 7.6355 -0.275  -4.5066  4.1661  6.6105  0.1761  0.4742  1.5051 -4.3174\n",
      "  1.9069]\n",
      "  f(w):  13.105984215785769\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.999756841554901)\n",
      "70. w:  [ 8.4649  7.3451  2.902   7.9294 -1.1567 -3.6143  7.5624  7.8909 -4.0172\n",
      "  5.2012]\n",
      "  f(w):  15.712234896946345\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "71. w:  [ 5.0991  0.4319 -1.4461  7.8009 -2.7412  4.3467 -0.2671 -1.2714 -3.3914\n",
      " -4.4973]\n",
      "  f(w):  12.76164600322942\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "72. w:  [ 5.9846 -0.2655  9.5726  6.4923 -0.289  -4.905   7.3787  4.9998  3.2478\n",
      " -0.3063]\n",
      "  f(w):  14.87413015459602\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (0.1717525103804187, 0.9999999900734892)\n",
      "73. w:  [-3.6854 -1.4328 -2.4932  0.3405  5.643   1.6467  6.3797  0.7702  8.8678\n",
      "  5.5595]\n",
      "  f(w):  14.062929867500454\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "74. w:  [ 1.244  -0.1087  1.1983  7.8198 -1.8821  5.261  -4.3511 -2.7314 -2.9633\n",
      "  6.8445]\n",
      "  f(w):  12.747830240826628\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "75. w:  [ 9.098   7.2224 -1.7534  3.6429  1.1201 -1.3451 -2.1771  1.5259  4.6835\n",
      "  2.4867]\n",
      "  f(w):  13.475271206706585\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9997638594248165)\n",
      "76. w:  [ 0.1545  4.2324 -0.1518  8.186  -1.7586 -2.6879 -4.0055 -4.391  -4.0839\n",
      "  8.1887]\n",
      "  f(w):  13.474141914323384\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "77. w:  [6.5406 7.1765 7.5719 8.6778 6.838  7.8866 9.066  4.0264 4.8988 9.8852]\n",
      "  f(w):  16.883023685835447\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "78. w:  [ 4.4134  2.2459  5.3128 -2.2402  6.4605  9.7922 -4.9367  8.7351  4.9954\n",
      "  9.8677]\n",
      "  f(w):  16.16672499943973\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9997664359506572)\n",
      "79. w:  [-1.9209  0.2856  5.6817 -1.1451 -3.0129  2.5228 -4.9002 -4.8469  0.8003\n",
      "  8.3515]\n",
      "  f(w):  12.748824937919617\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "80. w:  [ 5.8626  1.6095  0.2444 -4.9509 -4.8524  8.2939 -3.6501  1.0504  7.6835\n",
      " -2.0282]\n",
      "  f(w):  13.839057641107022\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "81. w:  [-0.2711 -4.8213 -0.1414  6.1716  7.6116  3.7724 -2.8846  6.9198  1.5255\n",
      "  9.9392]\n",
      "  f(w):  14.653347228923428\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (0.27348848573981355, 0.9999999606381367)\n",
      "82. w:  [ 2.0792 -0.045   2.4069  8.5817  1.73   -1.613   0.6404 -3.0241  6.744\n",
      "  4.5228]\n",
      "  f(w):  12.971917201358949\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "83. w:  [-1.1062  3.709   7.3826  8.0561  5.3257 -3.2238  8.8325 -2.9419  6.6725\n",
      "  1.1633]\n",
      "  f(w):  14.888116290639294\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "84. w:  [ 4.5243  4.1471 -4.1415 -2.443   5.1563 -1.7328  2.9889 -2.7582 -3.4662\n",
      "  8.4838]\n",
      "  f(w):  13.4818294788776\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9997748596175784)\n",
      "85. w:  [-4.1508  2.8524  4.8216 -0.6214  4.2952  7.4011  3.466   9.074   1.5893\n",
      " -4.7558]\n",
      "  f(w):  14.340199229185023\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "86. w:  [ 8.2742  3.2482  9.5531  6.8325  0.2638  5.4966  1.7875  4.0297 -4.1599\n",
      "  5.8735]\n",
      "  f(w):  15.168282240184592\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "87. w:  [-4.9347  0.3737 -1.8143  0.6586 -2.5938  7.1536  0.9011 -1.7839  5.9541\n",
      "  9.453 ]\n",
      "  f(w):  13.718476518810196\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9997741587718642)\n",
      "88. w:  [-4.521   5.7762 -0.4985 -1.3576  7.4631  0.3048 -2.5974 -1.2767  5.6645\n",
      " -0.1943]\n",
      "  f(w):  12.940703378175147\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "89. w:  [-4.0486 -4.7414 -2.9933  5.7834  4.1754  1.7887  6.9205  0.875   4.8393\n",
      "  3.1848]\n",
      "  f(w):  12.538340808714521\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "90. w:  [ 3.6446  9.0857 -2.4043  1.522  -2.8404  2.2112  9.4061 -1.4746  7.0747\n",
      " -2.1347]\n",
      "  f(w):  14.635433896518531\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (0.02213428855081543, 1.00000004365124)\n",
      "91. w:  [ 4.0535  0.0592 -1.4427 -0.0873  5.729   3.3966  3.7153  2.7238  1.4843\n",
      "  1.6017]\n",
      "  f(w):  10.823607607660342\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "92. w:  [ 4.2366 -3.6398 -3.5066  1.3847 -0.4745  5.0466  6.8945 -4.3916  0.9918\n",
      " -1.2813]\n",
      "  f(w):  12.409843753317046\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "93. w:  [ 5.9603  8.1663 -2.5496  4.4476  4.4735  7.1387 -0.5478  0.7874  8.0783\n",
      "  7.8588]\n",
      "  f(w):  15.347869701413932\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (1.3353706310847775, 0.9999998751440974)\n",
      "94. w:  [-4.7048 -1.9607  3.7405 -2.4923 -1.8884  8.4957 -3.9021  4.6691 -3.199\n",
      " -0.4308]\n",
      "  f(w):  13.019871762283376\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "95. w:  [ 1.5706  2.7232  5.9157  5.5752  7.8333 -3.0508  2.108   4.378   9.9726\n",
      " -1.0711]\n",
      "  f(w):  14.396972090473534\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "96. w:  [-1.2543 -3.0976 -3.4007  2.5291  1.9006  1.2269  8.3551 -1.9579 -0.6131\n",
      "  3.5062]\n",
      "  f(w):  11.866413705570643\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (0.2595749427158624, 1.000001180167623)\n",
      "97. w:  [ 6.694  -3.835   5.8251  3.5388 -0.5566  9.7056 -0.659   3.8822 -0.3219\n",
      " -2.6025]\n",
      "  f(w):  14.167385640542918\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "98. w:  [-0.8553  9.6514  0.7099 -2.6957 -0.778  -3.2854  8.0871  7.7207  1.1057\n",
      "  1.1742]\n",
      "  f(w):  14.079487074864064\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "99. w:  [ 5.1923  4.7965  2.3139 -4.4139 -2.5187  4.3216 -1.5191  4.0734  9.8616\n",
      " -3.6665]\n",
      "  f(w):  14.224798045950868\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (0.677898615257327, 0.9999999914103899)\n",
      "100. w:  [ 7.1916  2.6992 -2.849   8.8321  6.9053  7.3435  8.2702  6.6346  7.739\n",
      "  7.5422]\n",
      "  f(w):  16.72739510844878\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "101. w:  [ 8.208  -2.6261  0.9004  4.4685 -3.2515 -1.5151 -0.3989  2.7229  6.9089\n",
      " -2.8273]\n",
      "  f(w):  13.096405728021152\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "102. w:  [ 0.2568  5.8552  5.1222  0.664   5.3966  3.5435  4.6804  2.6552 -3.6772\n",
      "  7.4927]\n",
      "  f(w):  13.854371576483011\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (0.7979892763105367, 1.0000000694694169)\n",
      "103. w:  [ 5.5903 -4.6794 -2.9191  5.5396 -0.6778  2.2936  6.1737 -4.9729  4.6523\n",
      "  7.6571]\n",
      "  f(w):  14.390002284651532\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "104. w:  [-3.4363 -0.3016  8.9943  3.9943  6.9765  0.5837  6.3404 -2.0786  7.5987\n",
      "  6.8671]\n",
      "  f(w):  15.002724349648698\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "105. w:  [ 2.9951 -1.942  -0.571   7.8953  1.7757 -4.1557  9.9779 -0.5957  9.7354\n",
      " -1.3714]\n",
      "  f(w):  14.724115816288101\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (0.03202201876937912, 1.0000000081064218)\n",
      "106. w:  [-0.8283 -4.9703  9.7796  5.7343 -4.1146 -4.7841 -2.0423  2.1321  2.9749\n",
      "  6.3279]\n",
      "  f(w):  13.78624585481917\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "107. w:  [ 2.5769 -1.2483  7.0129  8.7683  8.7787  1.9122  1.3071  1.2993 -4.9546\n",
      "  0.3438]\n",
      "  f(w):  14.150069522528305\n",
      "  y_best:  9.647632107904009\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108. w:  [ 8.9659  1.4594  4.8498  9.7979  5.5023  5.6196 -2.6438 -1.9207 -0.6272\n",
      "  2.3683]\n",
      "  f(w):  14.962241725194941\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (0.5405869325550121, 0.9999997917718901)\n",
      "109. w:  [ 0.904   2.4655  8.8249  4.5083  4.5666 -2.6822  0.975   1.0449  1.8887\n",
      " -2.349 ]\n",
      "  f(w):  12.351243019189447\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "110. w:  [-3.7682 -1.477   9.0385  3.5885  6.4691  4.8319 -2.9018  6.8395  5.9398\n",
      "  0.0217]\n",
      "  f(w):  14.372970241652068\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "111. w:  [ 3.2503  3.4048  7.2971  5.9731 -2.2325  0.9552  6.9746  5.3146 -4.6826\n",
      "  6.7321]\n",
      "  f(w):  14.41497781135115\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (0.4141303199509775, 0.9999997999783554)\n",
      "112. w:  [ 5.0637 -2.5097  1.4028  8.0104  7.587   4.1263  8.7855  2.245   0.3354\n",
      " -2.8714]\n",
      "  f(w):  14.511788332113944\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "113. w:  [ 1.7115 -0.3857  1.7157  0.9161  0.988   1.3037 -3.8065  8.459   8.0337\n",
      " -0.8547]\n",
      "  f(w):  12.612649206980592\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "114. w:  [ 5.5858 -3.372   8.3418  0.8725 -1.4424  7.4498  4.1418 -3.0061  7.3831\n",
      "  4.3298]\n",
      "  f(w):  14.89337170429621\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (0.47715058695336504, 0.9999999738390261)\n",
      "115. w:  [-1.0749  0.6541  3.0842  4.0825  4.8989  3.4458  2.1928 -3.0747  0.1398\n",
      "  2.8449]\n",
      "  f(w):  10.046626961770656\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "116. w:  [ 1.8939  7.5696 -2.6669  6.9171  7.839  -1.2535  5.8263 -2.5391  4.2876\n",
      "  0.3483]\n",
      "  f(w):  14.231004436192729\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "117. w:  [-0.9403  8.3635  5.3807  6.5929 -4.9106  5.9709  6.4293  4.5921  9.2022\n",
      "  2.2144]\n",
      "  f(w):  15.71013235775392\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9993342091659384)\n",
      "118. w:  [ 4.0605 -4.5805  0.7785  5.5656 -3.8758  2.2329 -1.861  -0.3054  1.9293\n",
      " -0.2592]\n",
      "  f(w):  10.83334942185247\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "119. w:  [-2.2628 -3.1714 -1.4201 -0.8656 -2.2492 -1.9797 -1.7477  2.8738  2.86\n",
      "  1.8441]\n",
      "  f(w):  8.561644727531025\n",
      "  y_best:  9.647632107904009\n",
      "\n",
      "120. w:  [-4.4597  6.5981 -2.8527 -1.2069  1.9463  7.048   0.3919 -4.4109  1.6561\n",
      "  6.9174]\n",
      "  f(w):  13.5127724157712\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9992735481211465)\n",
      "121. w:  [-1.8224  4.4921 -1.9618 -1.7803  3.8885  2.3412  3.9589  6.4574  9.9524\n",
      "  6.82  ]\n",
      "  f(w):  14.172880861490007\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "122. w:  [ 8.9327  5.2693  8.7337  5.1073  9.6872 -1.9989 -2.0543 -1.1633 -0.7097\n",
      "  3.6234]\n",
      "  f(w):  15.050472451290652\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "123. w:  [-2.0902 -2.697  -0.1665 -4.8274 -3.0722 -0.9445 -0.8725  3.8951  2.8897\n",
      " -2.5687]\n",
      "  f(w):  9.607430831978114\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.04003964370342344, 0.9999999944969662)\n",
      "124. w:  [ 2.6096 -2.9293 -4.0461  2.6864  9.0679 -3.2027 -4.3166 -0.082  -4.9179\n",
      "  9.1926]\n",
      "  f(w):  14.05596932513515\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "125. w:  [ 6.9762  8.5745 -4.9274  1.2381 -2.9144  7.0624  5.8996  1.5314  6.3924\n",
      "  5.5741]\n",
      "  f(w):  15.108479306516504\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "126. w:  [ 3.1272 -4.4103  0.5687  3.2608  3.106  -4.5262 -4.3293 -3.518  -2.937\n",
      "  8.682 ]\n",
      "  f(w):  13.470210950887536\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.8852906511580086, 1.0000000490426006)\n",
      "127. w:  [-0.9678 -3.4364 -2.0126  6.8609  2.2304 -0.529  -3.1219  2.0262  1.4716\n",
      "  9.6042]\n",
      "  f(w):  13.024520183369132\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "128. w:  [ 9.4151  1.291   8.9302  9.1254  2.8032  0.6653 -0.1069  4.4337  5.5119\n",
      " -1.4533]\n",
      "  f(w):  15.357272572148732\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "129. w:  [-4.4069  5.469   1.3123  0.1097  1.8187 -1.425   9.0988  6.7608 -0.4294\n",
      "  4.4978]\n",
      "  f(w):  13.890585855703257\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9984791869535978)\n",
      "130. w:  [-0.1127 -3.853   9.6902  1.2975 -4.1146  6.9406 -4.7323  2.8454  3.3282\n",
      "  7.2834]\n",
      "  f(w):  14.405095378970326\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "131. w:  [-2.1979  4.4063  4.9384 -4.3117 -3.4913  2.2795 -4.1547 -1.3099  9.7732\n",
      "  5.3686]\n",
      "  f(w):  14.15845349375271\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "132. w:  [-0.2365  1.3317 -2.3146  2.6104  8.4892  1.9752  2.8788  8.6358 -1.7915\n",
      "  3.3659]\n",
      "  f(w):  13.478178403158646\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.542607911033437, 0.9999999777838535)\n",
      "133. w:  [ 6.4713  5.898   1.5551  0.0954  3.7855  3.5094 -3.6587  1.3537 -4.3565\n",
      "  1.792 ]\n",
      "  f(w):  12.5616119055326\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "134. w:  [ 7.0073 -0.3703  6.1488 -2.906  -3.8119  0.5008  3.4067  7.7787  0.2464\n",
      "  3.6727]\n",
      "  f(w):  13.464503812136364\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "135. w:  [ 9.9555  6.0412  4.3295  4.8517  4.8892 -0.284   2.1495  2.3389  7.2547\n",
      "  1.9793]\n",
      "  f(w):  14.18691187540156\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.21383396186443418, 0.9999999821031755)\n",
      "136. w:  [ 7.5849  7.3741 -3.5714  3.8151  4.9528 -4.2187 -0.8321 -2.5501  3.1222\n",
      "  0.1231]\n",
      "  f(w):  13.507766249574857\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "137. w:  [ 9.049  -0.7677 -1.6704 -4.1667  0.5919 -2.9252  1.6517 -4.8352  9.6957\n",
      "  0.4187]\n",
      "  f(w):  14.096711962545564\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "138. w:  [-2.2554 -0.8794  7.4506  4.2568  3.4534  8.2501  1.7111  2.0747  4.2096\n",
      " -1.9   ]\n",
      "  f(w):  13.270508045456697\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9984991149837179)\n",
      "139. w:  [ 8.5319  5.7742 -2.9033 -0.0577  8.1343 -0.6666  0.2361  5.3243 -4.8476\n",
      "  6.5291]\n",
      "  f(w):  14.688027294752455\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "140. w:  [ 8.6162  8.2352  2.6549 -1.954   0.2094 -1.6159 -0.2752  8.79    2.4053\n",
      " -0.6524]\n",
      "  f(w):  14.383584873685336\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "141. w:  [ 5.7859  3.8036  3.6683  3.6335 -3.5065  1.3065  9.0281  8.7805 -1.0049\n",
      " -0.9834]\n",
      "  f(w):  14.219270570560248\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.43105620888677765, 1.0000000021571198)\n",
      "142. w:  [ 7.6307 -2.5967  5.5097  8.4056  3.9305 -3.5799  4.8919  3.3752 -1.8123\n",
      "  0.5227]\n",
      "  f(w):  14.422430437703433\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "143. w:  [ 9.4713  8.671   0.1437 -0.2145  9.1032  2.9828 -4.7379  7.4372  8.7455\n",
      "  7.4505]\n",
      "  f(w):  16.69325894867389\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "144. w:  [ 1.8421  6.7684 -3.491   2.7485  8.0243  3.7556  4.7825  2.4661  1.667\n",
      " -2.6691]\n",
      "  f(w):  13.384986033538553\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.30154389629862177, 0.9999999509761699)\n",
      "145. w:  [ 5.019   2.171   9.8692  0.1887 -2.5905  7.259   2.8169 -3.5875  2.4998\n",
      "  4.683 ]\n",
      "  f(w):  14.166909272272028\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "146. w:  [ 0.2869 -3.9282  2.2623  9.7496  7.0628 -0.0366 -0.3464  0.4096 -2.586\n",
      "  9.5175]\n",
      "  f(w):  14.623681384883092\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "147. w:  [ 2.6688  7.8076 -0.1009 -1.1972  2.9497  6.0619 -3.9777  2.7605  2.6562\n",
      "  4.1612]\n",
      "  f(w):  12.316450581859812\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.3992010723280602, 0.9999999456889093)\n",
      "148. w:  [ 8.1314  4.7041  2.0686 -2.8924  5.3059  6.3814  9.5622  7.1205  8.048\n",
      " -1.3411]\n",
      "  f(w):  15.745152162749775\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "149. w:  [ 5.4272 -2.4268  3.8718  3.7969 -0.0945 -3.984   4.4442 -3.6109  7.5801\n",
      "  0.0258]\n",
      "  f(w):  13.025456795804226\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "150. w:  [ 1.9236  5.2925  3.7233  8.7945  5.1006  2.4362 -4.2578 -0.0188  7.6029\n",
      "  2.5586]\n",
      "  f(w):  14.186472337153774\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9985517158093558)\n",
      "151. w:  [ 2.2356  6.2988 -1.8708  1.5761 -4.1066 -0.4478 -3.9082  9.6357 -4.7088\n",
      " -3.2775]\n",
      "  f(w):  13.777219586219427\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "152. w:  [-3.0855  3.1366 -4.8016 -1.1665  2.1592 -0.797   0.3911  4.7715  5.0573\n",
      "  0.7841]\n",
      "  f(w):  10.587479781405126\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "153. w:  [ 2.2567  2.0785  4.8519 -2.4236  2.8966  0.9244  0.0597 -0.7194 -2.2129\n",
      " -3.2103]\n",
      "  f(w):  9.237910819282817\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.6563935380251343, 0.9999999940104642)\n",
      "154. w:  [ 6.9379  4.4376  6.71    4.1832 -3.3911 -0.5687 -1.6001  1.7971  7.3739\n",
      " -3.3612]\n",
      "  f(w):  14.070278872966465\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "155. w:  [ 7.4588  9.3936  9.8438 -0.8967 -2.2777 -1.2862  7.5763 -4.1387 -2.8368\n",
      "  4.0679]\n",
      "  f(w):  15.527337932767969\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "156. w:  [ 6.2315 -3.4406  3.7342 -0.1552  7.6005  2.0755  0.149   4.0143  5.4543\n",
      "  5.339 ]\n",
      "  f(w):  13.578646202201314\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (1.1631998787303608, 1.000000114763662)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157. w:  [ 8.0071 -0.546  -1.6022  3.5097 -0.2311 -1.915   2.1834  2.9473  5.4076\n",
      " -0.8743]\n",
      "  f(w):  11.852825974210488\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "158. w:  [ 8.1743  4.9979 -0.2292  7.215   4.4802  1.3067 -2.8826  2.4956 -4.4612\n",
      "  2.571 ]\n",
      "  f(w):  13.81618339211242\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "159. w:  [-1.8272 -2.7431  1.3168  7.8705  2.3147 -0.4539  7.368  -3.6816  0.5337\n",
      "  7.705 ]\n",
      "  f(w):  13.937053389112867\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.11335976919392692, 1.0000001613746003)\n",
      "160. w:  [1.2842 8.333  6.724  8.5464 4.1216 7.7735 6.7484 8.1427 6.8795 1.3261]\n",
      "  f(w):  16.319074838383333\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "161. w:  [-1.3369  0.2036 -4.5978  1.3343 -3.391   6.0568 -2.4938  9.4119  0.7552\n",
      "  6.2504]\n",
      "  f(w):  13.948614978448248\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "162. w:  [ 9.6474  2.899  -2.5886  1.455   7.0048 -3.379   1.5569  8.5708  8.2226\n",
      "  3.6298]\n",
      "  f(w):  15.658503229528659\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.9023521054070449, 0.9999999933506376)\n",
      "163. w:  [ 4.8123 -4.7585 -4.9941  2.0443  1.4544  7.5308 -4.5692  8.0239  5.8462\n",
      "  2.6099]\n",
      "  f(w):  14.471020978159865\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "164. w:  [ 5.8262  5.9665  9.0104  6.1071 -3.1582  6.5634  8.5073  7.2327  8.0536\n",
      " -1.2887]\n",
      "  f(w):  16.044504614411935\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "165. w:  [ 9.9854 -3.1524 -2.0047  3.3108  6.199   7.3181 -2.2629  7.6635  7.6807\n",
      "  3.8244]\n",
      "  f(w):  15.469179728965843\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.5686810899289952, 1.0000001363565731)\n",
      "166. w:  [ 6.3125  9.5745  9.7382 -0.9596  5.1826  8.9568 -0.701   6.518  -3.5239\n",
      "  0.3802]\n",
      "  f(w):  16.164557173913956\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "167. w:  [-4.9271 -3.4379 -3.7551 -4.1617  8.0776  4.2213  4.5871  2.1389  4.8489\n",
      "  0.5796]\n",
      "  f(w):  13.427483355401476\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "168. w:  [ 4.2931  3.1123  2.4829  0.3538  0.1173  0.0774 -1.7156 -3.4113  7.4492\n",
      " -3.0866]\n",
      "  f(w):  11.600758468563493\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (1.0928897275186256, 1.0000000134166591)\n",
      "169. w:  [ 1.228  -2.3084 -2.25   -2.6815  0.5834  0.4763 -4.2281  7.6141  0.5138\n",
      "  8.6734]\n",
      "  f(w):  13.338245991693023\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "170. w:  [-3.083   8.1596 -3.2282 -0.457   5.1154 -3.2113 -3.0678 -0.1804 -3.9757\n",
      "  4.746 ]\n",
      "  f(w):  12.499076338593202\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "171. w:  [ 1.3201 -0.4083  3.2254  5.9104  2.9247  0.8521 -0.9764 -1.496   6.7452\n",
      "  4.8724]\n",
      "  f(w):  11.759172137362391\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9978546248229767)\n",
      "172. w:  [-4.6883 -0.7309 -1.9718  6.2834  0.2543 -3.0166  9.7041  0.0365 -0.9672\n",
      "  0.6564]\n",
      "  f(w):  12.696583549101577\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "173. w:  [-1.1888 -4.7678 -0.9158  1.8228 -2.8256 -4.4594 -1.9476  0.5898 -1.8648\n",
      "  7.8396]\n",
      "  f(w):  11.570102314926505\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "174. w:  [ 8.1955 -0.4202  6.1473 -0.5678  2.2839  3.7482 -0.724   3.636  -3.2063\n",
      "  9.0841]\n",
      "  f(w):  14.147221971614222\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.5850413039238013, 1.0000000244890461)\n",
      "175. w:  [ 7.4667  0.2617  3.7244 -0.4185 -3.9573  5.5867  9.7093  7.8973  7.9941\n",
      " -0.7969]\n",
      "  f(w):  15.478698573180026\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "176. w:  [ 4.1463  2.0125 -0.527   0.8365 -1.467  -0.6816 -4.9338  9.477  -1.092\n",
      " -1.9462]\n",
      "  f(w):  12.198843406567315\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "177. w:  [ 8.2164  7.3941  3.7333  0.8143 -4.3119 -3.0551  2.2189  8.5319  2.5498\n",
      "  9.7615]\n",
      "  f(w):  15.661908626376778\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (1.0479607506818316, 0.9999988548575176)\n",
      "178. w:  [ 6.5498 -2.6193  2.8447  8.3755 -2.1701 -0.7305  6.055  -0.3825  0.2201\n",
      "  9.7501]\n",
      "  f(w):  14.680074883922948\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "179. w:  [ 1.0647  7.7171  3.7945  2.2486 -4.8944  1.2503 -1.1472 -1.0599  8.4418\n",
      "  2.2562]\n",
      "  f(w):  12.982146316347324\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "180. w:  [-4.6775  1.7043 -0.23    3.3695  8.3532 -3.8446 -4.5944 -2.9198 -1.1552\n",
      " -4.1322]\n",
      "  f(w):  12.928648460033465\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9978720048201082)\n",
      "181. w:  [ 4.7069 -3.984  -3.8438  5.2211  3.4632  6.4868  8.5547 -0.1554  7.509\n",
      "  5.8975]\n",
      "  f(w):  15.115151590670752\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "182. w:  [ 5.8667 -1.6503  6.5265 -1.6371  5.4287 -2.3542  5.9748  6.6663 -0.1623\n",
      " -0.9112]\n",
      "  f(w):  13.626287987234525\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "183. w:  [-4.6708  2.9141  9.1033  6.9331  6.5541  4.0151  8.9622  8.4925 -2.2595\n",
      "  6.6696]\n",
      "  f(w):  16.096244515051307\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9978675518514822)\n",
      "184. w:  [ 3.0451  1.3191 -3.7985 -1.8493  4.3396  2.6933 -4.7092  3.8058 -0.2289\n",
      "  2.7487]\n",
      "  f(w):  10.987710938554713\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "185. w:  [ 2.294  -3.6681 -2.5746 -4.4267 -4.6969  5.8865 -2.5365  4.3132 -0.2682\n",
      "  3.7913]\n",
      "  f(w):  12.567950724534311\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "186. w:  [ 6.4401  5.4487 -3.5854  3.2636  4.5882 -3.4749 -4.3642  9.8154 -2.1641\n",
      " -1.1426]\n",
      "  f(w):  14.663340082835411\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9979461848530728)\n",
      "187. w:  [ 8.9335  4.9437  6.9753  8.0003  0.876  -2.7402  3.7872  8.1851  3.672\n",
      "  1.6873]\n",
      "  f(w):  14.76718879684915\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "188. w:  [ 6.8975  8.7132  6.5706  1.4316  0.5293  2.3876 -0.0488  9.9383 -0.5686\n",
      "  4.7324]\n",
      "  f(w):  15.175092929163991\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "189. w:  [ 3.733   7.2565 -1.6272  0.9574  2.8217  3.4957  7.2175 -4.9327  7.7844\n",
      "  0.7223]\n",
      "  f(w):  13.946228040331661\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.48853571299258397, 0.9999999787489298)\n",
      "190. w:  [ 9.2867 -0.3742  8.3368  2.8755  8.9958  2.3659  5.8114  6.5904  8.2717\n",
      "  2.4616]\n",
      "  f(w):  16.273738247881177\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "191. w:  [ 4.1009  1.7019  3.46    3.7384  9.2436  3.7526  0.699   8.7741  8.3893\n",
      " -3.2379]\n",
      "  f(w):  15.198019433891936\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "192. w:  [ 5.5206 -4.0761  7.2745  4.2618  4.1621  6.6186  9.2967 -2.9587  9.9494\n",
      "  5.3994]\n",
      "  f(w):  16.068130168339547\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9979366287482387)\n",
      "193. w:  [ 8.0985 -3.6711  5.9174 -4.5471 -3.9662  4.6734  1.3269  8.5049  5.1511\n",
      "  8.2186]\n",
      "  f(w):  15.48465553291409\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "194. w:  [ 2.9199  3.4614  2.7296 -1.2076 -1.4131  5.0584  1.9603  9.2925  3.6276\n",
      "  7.6667]\n",
      "  f(w):  13.912556675704113\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "195. w:  [-2.6004  2.8139 -4.6324  8.2537  7.3129  7.6038 -0.9028  6.5991  1.6829\n",
      " -4.4999]\n",
      "  f(w):  15.125529765227492\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9979298054473885)\n",
      "196. w:  [7.8219 1.555  9.191  1.8572 7.6344 6.26   0.1919 2.747  6.3014 5.4886]\n",
      "  f(w):  15.45382354560584\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "197. w:  [ 6.8711  4.208   9.4883  9.9306  8.3153  7.7034  8.715   5.4178 -3.5423\n",
      "  5.5509]\n",
      "  f(w):  17.306075868925127\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "198. w:  [ 5.7367  0.7911 -4.7212 -1.0093  4.5197 -4.4532  5.2941 -2.2161 -1.4204\n",
      " -4.6848]\n",
      "  f(w):  12.800029387889415\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9979404683858654)\n",
      "199. w:  [ 8.9194  0.1341  0.8849  9.1347 -0.8569  7.8997  4.7512  6.7458  9.2863\n",
      "  3.3631]\n",
      "  f(w):  15.58891306065776\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "200. w:  [ 8.6744  1.671  -0.9205  3.7303  8.4557  7.1004 -1.913   1.8765  4.5709\n",
      "  6.4573]\n",
      "  f(w):  14.896921297690731\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "201. w:  [ 7.9045 -2.4029  9.5788  4.6739  0.2579  5.1275  3.4082  2.2401 -1.1474\n",
      "  3.0422]\n",
      "  f(w):  14.129397524786178\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9979244381248387)\n",
      "202. w:  [-1.3573  4.3407  7.6933  4.3331  0.6615  5.9752  5.7002 -3.6008  1.9733\n",
      "  5.5412]\n",
      "  f(w):  14.03621592178578\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "203. w:  [ 1.4441  1.7561  7.8684  8.3739 -4.8617  5.7252  2.2522  6.083   9.5501\n",
      "  2.5149]\n",
      "  f(w):  15.55575705138562\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "204. w:  [ 5.1498 -0.2724  2.2923 -0.8567  2.2848  8.0966  6.3808 -2.0351  7.1442\n",
      "  6.5602]\n",
      "  f(w):  14.101813293034391\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9979203738995692)\n",
      "205. w:  [-0.8655 -2.719   2.2306  5.8769 -1.4458 -0.5386  7.2809  2.0652  3.567\n",
      "  4.4222]\n",
      "  f(w):  12.399327184287564\n",
      "  y_best:  8.561644727531025\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206. w:  [-4.256  -3.6885  1.6796  8.0072  4.1123  0.5884 -3.4658  0.5544  4.3569\n",
      "  3.2187]\n",
      "  f(w):  12.880564075571979\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "207. w:  [-0.3621 -2.5829  8.243  -1.8504 -4.1462 -2.1817  2.0913  7.2818 -4.0397\n",
      " -3.7482]\n",
      "  f(w):  13.123244750528434\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.7056917247126596, 0.9999999973367932)\n",
      "208. w:  [-4.5288 -0.0347  0.4526  3.2929 -0.8281  0.6536 -3.9818  4.9883  5.4929\n",
      " -1.6464]\n",
      "  f(w):  11.38868105550549\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "209. w:  [-4.6335  5.9896  6.0151  2.9782  4.341  -2.5491  7.3855  5.5177  2.3968\n",
      "  6.2013]\n",
      "  f(w):  14.593632509956668\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "210. w:  [ 6.1281 -4.5432  7.2625  7.323   5.8744 -1.7453  2.9082  7.7809  8.9607\n",
      " -4.729 ]\n",
      "  f(w):  15.638364420091523\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.6541203690178549, 0.999999951620793)\n",
      "211. w:  [ 5.1225 -1.5263 -1.0112  7.3467  1.54    6.9994 -1.609   4.6814  8.0811\n",
      "  2.3548]\n",
      "  f(w):  14.129977876508057\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "212. w:  [ 1.4651  5.6606  3.3884 -0.5267 -4.1899  9.9368  0.3285  4.6615 -2.8816\n",
      "  1.4483]\n",
      "  f(w):  13.711701361424877\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "213. w:  [ 2.7305  6.6035 -0.5182  3.6278 -3.4837 -3.4731 -1.0862  9.6956  6.319\n",
      " -0.5963]\n",
      "  f(w):  14.371357394376505\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.22217622762355588, 1.000000050752537)\n",
      "214. w:  [-0.0281  5.2354 -0.8813 -1.7663 -3.1825  2.873   5.8658  0.5024  0.158\n",
      "  7.6689]\n",
      "  f(w):  12.018954937792572\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "215. w:  [ 1.8745  4.7391  5.686   5.4194  7.0903 -3.8972  7.8313  9.0665 -3.7781\n",
      " -3.257 ]\n",
      "  f(w):  14.994050984203245\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "216. w:  [ 7.2496  3.1818  0.2507  1.4545  5.5833  2.0452 -0.3305 -0.7659 -2.0846\n",
      "  8.5545]\n",
      "  f(w):  13.213311971424964\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.5126810887181849, 1.0000007736523335)\n",
      "217. w:  [ 3.1239 -4.9184  1.7186  5.8002 -4.5235  2.6013  3.7172  6.2561  6.729\n",
      "  0.558 ]\n",
      "  f(w):  13.604641624253116\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "218. w:  [ 1.2656 -2.121  -4.7065  7.2462 -4.6602  9.3938 -1.3576  6.7271 -1.483\n",
      " -0.8818]\n",
      "  f(w):  14.401218000374486\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "219. w:  [ 8.8597  6.936   8.2916  6.56    9.5507  7.3921 -0.202   0.1197  2.3514\n",
      "  8.6876]\n",
      "  f(w):  16.729703981694797\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9980287259262636)\n",
      "220. w:  [-4.0635 -1.973   1.7474 -1.4175 -4.1344 -3.6345  3.9187  7.6428  1.9123\n",
      "  4.1587]\n",
      "  f(w):  12.206605297814813\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "221. w:  [ 8.4999  0.1545  1.989   9.3883  2.8816 -1.0868 -2.8842  4.9642  9.081\n",
      "  6.336 ]\n",
      "  f(w):  14.957504248544026\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "222. w:  [-3.5901  9.074   4.4478  1.4412  1.6091  9.7776  9.6962  2.8826  4.4432\n",
      "  4.0943]\n",
      "  f(w):  15.82649858983709\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (2.0, 0.9980454852346848)\n",
      "223. w:  [ 8.627   0.1918  7.6879 -2.859  -2.7617 -2.3544  2.2103  4.5365  5.9398\n",
      "  5.6652]\n",
      "  f(w):  14.416246765010138\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "224. w:  [-4.5255  2.2837 -3.5275  1.5965 -3.6895 -1.5801 -0.8466 -0.659  -1.9623\n",
      "  1.6169]\n",
      "  f(w):  10.00856647550666\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "225. w:  [-3.0001  8.7551  7.5016 -1.1894  8.3824  8.5154 -4.3195  5.2306  0.1813\n",
      "  2.4863]\n",
      "  f(w):  15.667902618652148\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (0.08290562365354899, 1.0000001333770712)\n",
      "226. w:  [-2.2625 -2.9222 -2.5458  0.851   2.2159 -2.0987  1.6405 -4.7371 -1.0289\n",
      "  0.0257]\n",
      "  f(w):  8.966090308474381\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "227. w:  [ 0.8924  1.7306 -2.0098  5.2964 -0.6385  4.7982 -0.7622 -0.0503 -1.9973\n",
      " -0.5145]\n",
      "  f(w):  9.438920165697784\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "228. w:  [ 5.7493 -4.7386  4.9411  5.742   7.6339  6.5762 -1.2612 -2.5101  6.5927\n",
      "  9.5999]\n",
      "  f(w):  15.96607451588066\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "  # Optimal (ls, var) =  (1.1259790549511415, 0.9999680195028754)\n",
      "229. w:  [ 4.2467 -0.4849  0.7034  0.9387 -2.5623  7.2384  5.2831 -3.4901 -1.5424\n",
      "  6.2626]\n",
      "  f(w):  13.029201343331815\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "230. w:  [ 9.7508  3.8618  1.3469  6.4931  2.9803  4.0747  8.5218 -3.7137  5.8531\n",
      "  8.8781]\n",
      "  f(w):  15.766127837998656\n",
      "  y_best:  8.561644727531025\n",
      "\n",
      "231. w:  [ 6.0948 -0.4292  2.3109  2.0968 -1.1816  7.9817  8.9306  7.2298 -3.0998\n",
      "  8.3611]\n",
      "  f(w):  14.960959632436717\n",
      "  y_best:  8.561644727531025\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/hangdong/anaconda3/envs/BO/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-21-46d9a4d6ddf1>\", line 72, in <module>\n",
      "    ls, var = gp.optimize()\n",
      "  File \"/home/hangdong/gp/Code/GP.py\", line 150, in optimize\n",
      "    loglik = np.append(loglik, self.log_lik(hyper_values=x))\n",
      "  File \"/home/hangdong/gp/Code/GP.py\", line 126, in log_lik\n",
      "    KK_x_x = self.cov_RBF(self._X, self._X, hyper) + np.eye(len(self._X)) * self.noise_delta**2\n",
      "  File \"/home/hangdong/gp/Code/GP.py\", line 113, in cov_RBF\n",
      "    assert np.all(x2 >= self._B[:, 0]) and np.all(x2 <= self._B[:, 1])\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hangdong/anaconda3/envs/BO/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hangdong/anaconda3/envs/BO/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/hangdong/anaconda3/envs/BO/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/hangdong/anaconda3/envs/BO/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/hangdong/anaconda3/envs/BO/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/hangdong/anaconda3/envs/BO/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/hangdong/anaconda3/envs/BO/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/hangdong/anaconda3/envs/BO/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/hangdong/anaconda3/envs/BO/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/hangdong/anaconda3/envs/BO/lib/python3.8/posixpath.py\", line 425, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/hangdong/anaconda3/envs/BO/lib/python3.8/posixpath.py\", line 167, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-46d9a4d6ddf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gp/Code/GP.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mloglik\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloglik\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_lik\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gp/Code/GP.py\u001b[0m in \u001b[0;36mlog_lik\u001b[0;34m(self, hyper_values)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mKK_x_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov_RBF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_delta\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKK_x_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# NaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gp/Code/GP.py\u001b[0m in \u001b[0;36mcov_RBF\u001b[0;34m(self, x1, x2, hyper)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_B\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_B\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_B\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_B\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/BO/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BO/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2046\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2047\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BO/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1436\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BO/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/BO/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1193\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BO/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BO/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "cost = setup \n",
    "\n",
    "while cost < MAX:\n",
    "    # 1. Thompson Sampling\n",
    "    w = gp.thompson_sample(n_mesh=2000)\n",
    "    # 2. GP_UCB\n",
    "#     b = np.log(cost**gp.dim)\n",
    "#     w, fw = gp.ucb_minimize(b)\n",
    "#     w, fw = gp.EI_minimize(y_best=np.min(f(gp.X)))\n",
    "    if is_new(w, gp.X) == False:\n",
    "        print('visit before, ignore ', w)\n",
    "        continue\n",
    "    \n",
    "\n",
    "#     fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = pl.subplots(3, 2, figsize=(24, 21))\n",
    "\n",
    "#     # plot function (ax1, ax2)\n",
    "#     im = ax2.pcolormesh(X1, X2, s.reshape(X1.shape), cmap=\"jet\", shading='auto')\n",
    "#     fig.colorbar(im, ax=ax2)\n",
    "\n",
    "#     im1 = ax1.contour(X1, X2, functions.Ackley_2().func(Grid).reshape(X1.shape), cmap=\"PuBuGn\")\n",
    "#     im2 = ax1.contour(X1, X2, mu.reshape(X1.shape), cmap=\"YlOrRd\")\n",
    "\n",
    "#     fig.colorbar(im1, ax=ax1)\n",
    "#     fig.colorbar(im2, ax=ax1)\n",
    "\n",
    "#     ax1.plot(gp.X[:, 0], gp.X[:, 1], \"ok\", markersize=5, alpha=0.8)\n",
    "#     ax1.plot(w[0], w[1], 'ro')\n",
    "#     ax1.title.set_text(\"Noisy Ackley\")\n",
    "#     ax2.title.set_text(\"Standard Deviation\")\n",
    "    \n",
    "    \n",
    "#     # plot derivative in (ax3, ax4), (ax5, ax6)\n",
    "#     im = ax4.pcolormesh(X1, X2, s_grad_1.reshape(X1.shape), cmap=\"jet\", shading='auto')\n",
    "#     fig.colorbar(im, ax=ax4)\n",
    "#     im1 = ax3.contour(X1, X2, g1.reshape(X1.shape), cmap=\"PuBuGn\")\n",
    "#     im2 = ax3.contour(X1, X2, mu_grad_1.reshape(X1.shape), cmap=\"YlOrRd\")\n",
    "\n",
    "#     fig.colorbar(im1, ax=ax3)\n",
    "#     fig.colorbar(im2, ax=ax3)\n",
    "\n",
    "#     ax3.plot(gp.X[:, 0], gp.X[:, 1], \"ok\", markersize=5, alpha=0.8)\n",
    "#     ax3.title.set_text(\"Mean of Posterior Partial x\")\n",
    "#     ax4.title.set_text(\"Std of Posterior Partial x\")\n",
    "\n",
    "    \n",
    "#     im3 = ax6.pcolormesh(X1, X2, s_grad_2.reshape(X1.shape), cmap=\"jet\", shading='auto')\n",
    "#     fig.colorbar(im3, ax=ax6)\n",
    "#     im4 = ax5.contour(X1, X2, g2.reshape(X1.shape), cmap=\"PuBuGn\")\n",
    "#     im5 = ax5.contour(X1, X2, mu_grad_2.reshape(X1.shape), cmap=\"YlOrRd\")\n",
    "\n",
    "#     fig.colorbar(im4, ax=ax5)\n",
    "#     fig.colorbar(im5, ax=ax5)\n",
    "\n",
    "#     ax5.plot(gp.X[:, 0], gp.X[:, 1], \"ok\", markersize=5, alpha=0.8)\n",
    "#     ax5.title.set_text(\"Mean of Posterior Partial y\")\n",
    "#     ax6.title.set_text(\"Std of Posterior Partial y\")\n",
    "\n",
    "#     filename = 'Ackley_' + str(i) + '_noise_TS' +'.png'\n",
    "#     pl.savefig('2D_Plots/Ackley/' + filename)\n",
    "#     pl.show()  \n",
    "    print(cost, end = '. ')\n",
    "    print('w: ', w)\n",
    "    print('  f(w): ', f(w).item())\n",
    "    print('  y_best: ', np.min(f(gp.X)))\n",
    "    print()\n",
    "    \n",
    "    history_ucb.append( (w, f(w)) )\n",
    "    gp.add_data(w.reshape(1, dim), f(w))\n",
    "    \n",
    "    if cost % 3 == 0:\n",
    "        ls, var = gp.optimize()\n",
    "        gp.set_hyper(ls, var)\n",
    "        print('  # Optimal (ls, var) = ', (ls, var))\n",
    "    gp.fit()\n",
    "    cost += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(10, 7), dpi=80)\n",
    "pl.plot(np.squeeze(np.array(history_ucb)[:, 1]), \"-^\", lw=0.5)\n",
    "pl.plot(np.minimum.accumulate(np.array(history_ucb)[:, 1]), 'r', lw=2)\n",
    "pl.xlabel(\"cost\")\n",
    "pl.ylabel(\"function value\")\n",
    "pl.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Minima "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.X[np.argmin(gp.y)], np.min(gp.y), np.argmin(gp.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.get_hyper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(10, 7), dpi=80)\n",
    "pl.plot(np.minimum.accumulate([t[1].item() for t in history_ucb]), 'r', lw=3, label='Thompson')\n",
    "pl.plot(np.minimum.accumulate([t[1].item() for t in history]), 'b', lw=3, label='GD')\n",
    "# pl.title(\"6D Hartmann function on [0, 1]\")\n",
    "pl.legend()\n",
    "pl.grid(True)\n",
    "# pl.ylim([0, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = \"./pkl/GD_Ackley5.pkl\" \n",
    "\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(np.minimum.accumulate([t[1] for t in history]), open_file)\n",
    "open_file.close()\n",
    "\n",
    "open_file = open(file_name, \"rb\")\n",
    "loaded_list = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./pkl/thompson_Ackley5.pkl\" \n",
    "\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(np.minimum.accumulate([t[1] for t in history_ucb]), open_file)\n",
    "open_file.close()\n",
    "\n",
    "open_file = open(file_name, \"rb\")\n",
    "loaded_list = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
